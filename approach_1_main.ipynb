{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Copy of Copy of task_1_main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e47c611966844eadb2cfe926673e494e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_47c919f5b011483d8b602ba956990374",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_671f316ee5f2465eaf5267a1976b24e8",
              "IPY_MODEL_d5b7596f16804eeb8f8dd3b1073a06be"
            ]
          }
        },
        "47c919f5b011483d8b602ba956990374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "671f316ee5f2465eaf5267a1976b24e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_98c6870f0bc449b39f9d8653aa8d27cd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ac8e41d5b5f4ebb86a4531f549c435b"
          }
        },
        "d5b7596f16804eeb8f8dd3b1073a06be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_333167d4cc56449fa4869d2122c09135",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 807kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_78629d0ac788406b9c48e0074556096c"
          }
        },
        "98c6870f0bc449b39f9d8653aa8d27cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ac8e41d5b5f4ebb86a4531f549c435b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "333167d4cc56449fa4869d2122c09135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "78629d0ac788406b9c48e0074556096c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWRt9UuE3BQP"
      },
      "source": [
        "### Coursework coding instructions (please also see full coursework spec)\n",
        "\n",
        "Please choose if you want to do either Task 1 or Task 2. You should write your report about one task only.\n",
        "\n",
        "For the task you choose you will need to do two approaches:\n",
        "  - Approach 1, which can use use pre-trained embeddings / models\n",
        "  - Approach 2, which should not use any pre-trained embeddings or models\n",
        "We should be able to run both approaches from the same colab file\n",
        "\n",
        "#### Running your code:\n",
        "  - Your models should run automatically when running your colab file without further intervention\n",
        "  - For each task you should automatically output the performance of both models\n",
        "  - Your code should automatically download any libraries required\n",
        "\n",
        "#### Structure of your code:\n",
        "  - You are expected to use the 'train', 'eval' and 'model_performance' functions, although you may edit these as required\n",
        "  - Otherwise there are no restrictions on what you can do in your code\n",
        "\n",
        "#### Documentation:\n",
        "  - You are expected to produce a .README file summarising how you have approached both tasks\n",
        "\n",
        "#### Reproducibility:\n",
        "  - Your .README file should explain how to replicate the different experiments mentioned in your report\n",
        "\n",
        "Good luck! We are really looking forward to seeing your reports and your model code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQN7xeP23BQW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9347a31c-3150-49ce-8220-2529bcb9c0e9"
      },
      "source": [
        "# You will need to download any word embeddings required for your code, e.g.:\n",
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "\n",
        "# For any packages that Colab does not provide auotmatically you will also need to install these below, e.g.:\n",
        "\n",
        "#! pip install torch"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-22 05:21:01--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-02-22 05:21:01--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-02-22 05:21:02--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: â€˜glove.6B.zipâ€™\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.02MB/s    in 6m 51s  \n",
            "\n",
            "2021-02-22 05:27:53 (2.00 MB/s) - â€˜glove.6B.zipâ€™ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXHhn8ABipCS",
        "outputId": "ea2e9d36-8b72-4885-ac9a-8a3c61d81218"
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip install torch\r\n",
        "!pip install skorch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.8MB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 34.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.2MB 47.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=abbf6923d6e147584d40a88203f473b5a1b5c5e8de095965caacc269b84c8549\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.2\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Collecting skorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/c7/2f6434f9360c91a4bf14ae85f634758e5dacd3539cca4266a60be9f881ae/skorch-0.9.0-py3-none-any.whl (125kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.41.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.7)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (1.0.0)\n",
            "Installing collected packages: skorch\n",
            "Successfully installed skorch-0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL0-upkD3BQY"
      },
      "source": [
        "# Imports\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from transformers import BertTokenizer, RobertaTokenizer, AdamW, BertConfig\n",
        "from transformers import BertModel, BertForSequenceClassification,  RobertaModel\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import codecs"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov0JGF5J3BQZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0ee2188-5682-45fd-f40d-f6abc959be8d"
      },
      "source": [
        "# Setting random seed and device\n",
        "SEED = 1\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "np.random.seed(SEED)\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "if use_cuda:\n",
        "  print(\"Using GPU.\")\n",
        "else:\n",
        "  print(\"Using CPU.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oZQFbuF3BQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e79a901d-30be-4a1c-ab62-a7eee604899a"
      },
      "source": [
        "# Load data\n",
        "\n",
        "!wget -O train.csv https://drive.google.com/u/0/uc?id=1UgrdjcHHZmAthjusQDAKoSqd37up-41f&export=download\n",
        "!wget -O dev.csv https://drive.google.com/u/0/uc?id=1rY6A0cN_cxAMK3aMHlTFWxhbcLFomvQL&export=download\n",
        "\n",
        "train_df = pd.read_csv('./train.csv')\n",
        "test_df = pd.read_csv('./dev.csv')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-22 12:13:37--  https://drive.google.com/u/0/uc?id=1UgrdjcHHZmAthjusQDAKoSqd37up-41f\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.197.102, 74.125.197.113, 74.125.197.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.197.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-00-cc-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/96kke9tf9kt82pdk15bme2p20lcajat9/1613995950000/13802342090854404605/*/1UgrdjcHHZmAthjusQDAKoSqd37up-41f [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-02-22 12:13:38--  https://doc-00-cc-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/96kke9tf9kt82pdk15bme2p20lcajat9/1613995950000/13802342090854404605/*/1UgrdjcHHZmAthjusQDAKoSqd37up-41f\n",
            "Resolving doc-00-cc-docs.googleusercontent.com (doc-00-cc-docs.googleusercontent.com)... 74.125.195.132, 2607:f8b0:400e:c09::84\n",
            "Connecting to doc-00-cc-docs.googleusercontent.com (doc-00-cc-docs.googleusercontent.com)|74.125.195.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 947914 (926K) [text/csv]\n",
            "Saving to: â€˜train.csvâ€™\n",
            "\n",
            "train.csv           100%[===================>] 925.70K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-02-22 12:13:38 (163 MB/s) - â€˜train.csvâ€™ saved [947914/947914]\n",
            "\n",
            "--2021-02-22 12:13:38--  https://drive.google.com/u/0/uc?id=1rY6A0cN_cxAMK3aMHlTFWxhbcLFomvQL\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.197.102, 74.125.197.113, 74.125.197.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.197.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0c-cc-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/f27iuj1f9bu9qmti9ihhs6eio24k17sf/1613995950000/13802342090854404605/*/1rY6A0cN_cxAMK3aMHlTFWxhbcLFomvQL [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-02-22 12:13:39--  https://doc-0c-cc-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/f27iuj1f9bu9qmti9ihhs6eio24k17sf/1613995950000/13802342090854404605/*/1rY6A0cN_cxAMK3aMHlTFWxhbcLFomvQL\n",
            "Resolving doc-0c-cc-docs.googleusercontent.com (doc-0c-cc-docs.googleusercontent.com)... 74.125.195.132, 2607:f8b0:400e:c09::84\n",
            "Connecting to doc-0c-cc-docs.googleusercontent.com (doc-0c-cc-docs.googleusercontent.com)|74.125.195.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 219349 (214K) [text/csv]\n",
            "Saving to: â€˜dev.csvâ€™\n",
            "\n",
            "dev.csv             100%[===================>] 214.21K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2021-02-22 12:13:39 (125 MB/s) - â€˜dev.csvâ€™ saved [219349/219349]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CylH-J33qTou"
      },
      "source": [
        "# Training and Evaluation Helpers\r\n",
        "Here we have the helper functions that define the training and evaluation cycle, with specialised functions for models which require inputs other than the traditional sentence + grade input (e.g. Bert)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TCwEEwS3BQd"
      },
      "source": [
        "# We define our training loop\n",
        "def train(train_iter, dev_iter, model, number_epoch, loss_fn):\n",
        "  \"\"\"\n",
        "  Training loop for the model, which calls on eval to evaluate after each epoch\n",
        "  \"\"\"\n",
        "  training_stats = []\n",
        "  print(\"Training model.\")\n",
        "\n",
        "  for epoch in range(1, number_epoch+1):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_sse = 0\n",
        "    no_observations = 0  # Observations used for training so far\n",
        "\n",
        "    for batch in train_iter:\n",
        "      feature, target = batch\n",
        "      feature, target = feature.to(device), target.to(device)\n",
        "\n",
        "      # for RNN:\n",
        "      model.batch_size = target.shape[0]\n",
        "      no_observations = no_observations + target.shape[0]\n",
        "      model.hidden = model.init_hidden()\n",
        "\n",
        "      predictions = model(feature).squeeze(1)\n",
        "      optimizer.zero_grad()\n",
        "      loss = loss_fn(predictions, target)\n",
        "      sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy())\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()*target.shape[0]\n",
        "      epoch_sse += sse\n",
        "\n",
        "    valid_loss, valid_mse, __, __ = eval(dev_iter, model)\n",
        "    epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
        "\n",
        "    print('| Epoch: %.2d | Train Loss: %.2f | Train RMSE: %.4f | \\\n",
        "    Val. Loss: %.2f | Val. RMSE: %.4f |' % (\n",
        "      epoch + 1, epoch_loss, epoch_mse**0.5, valid_loss, valid_mse**0.5\n",
        "    ))\n",
        "\n",
        "    training_stats.append({\n",
        "            'epoch': epoch + 1,\n",
        "            'train_loss': epoch_loss,\n",
        "            'train_rmse': epoch_mse**0.5,\n",
        "            'val_loss': valid_loss,\n",
        "            'val_rmse': valid_mse**0.5\n",
        "    })\n",
        "    return training_stats"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI36r1_Z1eZ8"
      },
      "source": [
        "# Train function specifically for Bert models (includes attention mask and token types during forward)\r\n",
        "def train_bert(train_loader, val_loader, model, epochs):\r\n",
        "  \"\"\"\r\n",
        "  Training loop for the Bert model, which expects an additional attention mask as part of the data loaders.\r\n",
        "  \"\"\"\r\n",
        "  training_stats = []\r\n",
        "  print(\"Training model.\")\r\n",
        "\r\n",
        "  for epoch_i in range(epochs):\r\n",
        "    total_train_loss = 0\r\n",
        "    model.train()\r\n",
        "\r\n",
        "    x_pred = np.array([])\r\n",
        "    x_true = np.array([])\r\n",
        "\r\n",
        "    # Training Loop\r\n",
        "    for step, batch in enumerate(train_loader):\r\n",
        "      b_input_ids = batch[0].to(device)\r\n",
        "      b_input_mask = batch[1].to(device)\r\n",
        "      b_labels = batch[2].to(device)\r\n",
        "\r\n",
        "      model.zero_grad()\r\n",
        "      out = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\r\n",
        "      loss = out.loss\r\n",
        "      logits = out.logits\r\n",
        "\r\n",
        "      total_train_loss += loss.item()\r\n",
        "      loss.backward()\r\n",
        "\r\n",
        "      # Log predicted and true for MSE & RMSE\r\n",
        "      logits = logits.detach().cpu().numpy()\r\n",
        "      label_ids = b_labels.cpu().numpy()\r\n",
        "      x_pred = np.append(x_pred, logits)\r\n",
        "      x_true = np.append(x_true, label_ids)\r\n",
        "\r\n",
        "      # Clip the norm of the gradients to 1.0 to help prevent the \"exploding gradients\" problem\r\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "      optimizer.step()\r\n",
        "      scheduler.step() # Linear scheduler is based on steps rather than epochs\r\n",
        "\r\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\r\n",
        "    train_rmse = mean_squared_error(x_true, x_pred, squared=False)\r\n",
        "\r\n",
        "    # Validation \r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    # Tracking variables \r\n",
        "    total_eval_accuracy = 0\r\n",
        "    total_eval_loss = 0\r\n",
        "    nb_eval_steps = 0\r\n",
        "\r\n",
        "    y_pred = np.array([])\r\n",
        "    y_true = np.array([])\r\n",
        "\r\n",
        "    # Evaluate data for one epoch\r\n",
        "    for batch in val_loader:\r\n",
        "      b_input_ids = batch[0].to(device)\r\n",
        "      b_input_mask = batch[1].to(device)\r\n",
        "      b_labels = batch[2].to(device)\r\n",
        "        \r\n",
        "      # Forward pass, calculate logit predictions\r\n",
        "      with torch.no_grad():        \r\n",
        "        out = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\r\n",
        "        loss = out.loss\r\n",
        "        logits = out.logits\r\n",
        "        total_eval_loss += loss.item()\r\n",
        "\r\n",
        "        # Move logits and labels to CPU\r\n",
        "        logits = logits.detach().cpu().numpy()\r\n",
        "        label_ids = b_labels.cpu().numpy()\r\n",
        "        y_pred = np.append(y_pred,logits)\r\n",
        "        y_true = np.append(y_true,label_ids)\r\n",
        "        \r\n",
        "    val_rmse = mean_squared_error(y_true, y_pred, squared=False)\r\n",
        "    avg_val_loss = total_eval_loss / len(val_loader)\r\n",
        "    \r\n",
        "    print('| Epoch: %.2d | Train Loss: %.2f | Train RMSE: %.4f | \\\r\n",
        "        Val. Loss: %.2f | Val. RMSE: %.4f |' % (\r\n",
        "          epoch_i + 1, avg_train_loss, train_rmse, avg_val_loss, val_rmse\r\n",
        "    ))\r\n",
        "\r\n",
        "    training_stats.append({\r\n",
        "            'epoch': epoch_i + 1,\r\n",
        "            'train_loss': avg_train_loss,\r\n",
        "            'train_rmse': train_rmse,\r\n",
        "            'val_loss': avg_val_loss,\r\n",
        "            'val_rmse.': val_rmse\r\n",
        "    })\r\n",
        "  return training_stats"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJeBxYW93BQd"
      },
      "source": [
        "# We evaluate performance on our dev set\n",
        "def eval(data_iter, model):\n",
        "  \"\"\"\n",
        "  Evaluating model performance on the dev set\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  epoch_sse = 0\n",
        "  pred_all = []\n",
        "  trg_all = []\n",
        "  no_observations = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in data_iter:\n",
        "      feature, target = batch\n",
        "      feature, target = feature.to(device), target.to(device)\n",
        "\n",
        "      # for RNN:\n",
        "      model.batch_size = target.shape[0]\n",
        "      no_observations = no_observations + target.shape[0]\n",
        "      model.hidden = model.init_hidden()\n",
        "\n",
        "      predictions = model(feature).squeeze(1)\n",
        "      loss = loss_fn(predictions, target)\n",
        "\n",
        "      # We get the mse\n",
        "      pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
        "      sse, __ = model_performance(pred, trg)\n",
        "\n",
        "      epoch_loss += loss.item()*target.shape[0]\n",
        "      epoch_sse += sse\n",
        "      pred_all.extend(pred)\n",
        "      trg_all.extend(trg)\n",
        "\n",
        "  return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO4PMTUl3BQd"
      },
      "source": [
        "# How we print the model performance\n",
        "def model_performance(output, target, print_output=False):\n",
        "  \"\"\"\n",
        "  Returns SSE and MSE per batch (printing the MSE and the RMSE)\n",
        "  \"\"\"\n",
        "  sq_error = (output - target)**2\n",
        "  sse = np.sum(sq_error)\n",
        "  mse = np.mean(sq_error)\n",
        "  rmse = np.sqrt(mse)\n",
        "\n",
        "  if print_output:\n",
        "    print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n",
        "\n",
        "  return sse, mse"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UWJ9Z96uay3"
      },
      "source": [
        "# Helper Functions\r\n",
        "\r\n",
        "Helper functions for preprocessing or during model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkYFRpHt3BQe"
      },
      "source": [
        "def create_vocab(data):\n",
        "  \"\"\"\n",
        "  Creating a corpus of all the tokens used\n",
        "  \"\"\"\n",
        "  tokenized_corpus = [] # Let us put the tokenized corpus in a list\n",
        "\n",
        "  for sentence in data:\n",
        "    tokenized_sentence = []\n",
        "\n",
        "    for token in sentence.split(' '): # simplest split is\n",
        "      tokenized_sentence.append(token)\n",
        "\n",
        "    tokenized_corpus.append(tokenized_sentence)\n",
        "\n",
        "  # Create single list of all vocabulary\n",
        "  vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
        "\n",
        "  for sentence in tokenized_corpus:\n",
        "    for token in sentence:\n",
        "      if token not in vocabulary:\n",
        "          vocabulary.append(token)\n",
        "\n",
        "  return vocabulary, tokenized_corpus"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu_7IziNqAPQ"
      },
      "source": [
        "def get_sentences(df, og_label='original', edit_label='edit'):\r\n",
        "  \"\"\"\r\n",
        "  Extract the original and new sentences + words from a dataframe\r\n",
        "  \"\"\"\r\n",
        "  p = r\"<(.*)\\/>\"\r\n",
        "  replace_regex = re.compile(p)\r\n",
        "  og_word = []\r\n",
        "  new_word = []\r\n",
        "  og_sentences = []\r\n",
        "  new_sentences = []\r\n",
        "\r\n",
        "  for s, w in df[[og_label, edit_label]].itertuples(index=False,name=None):\r\n",
        "    tokens = s.split(' ') # For each sentence get the words\r\n",
        "    m = replace_regex.search(str(s)) # Get the word to replace\r\n",
        "\r\n",
        "    assert not m is None # Couldn't regex match the replacement word\r\n",
        "\r\n",
        "    og_word.append(m.group(1))\r\n",
        "    new_word.append(w)\r\n",
        "    og_sentences.append(replace_regex.sub( m.group(1), s))\r\n",
        "    new_sentences.append(replace_regex.sub(w, s))\r\n",
        "  \r\n",
        "  return og_sentences, new_sentences, og_word, new_word\r\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_xUhSV43BQe"
      },
      "source": [
        "def softmax_mask(batch, mask):\n",
        "    normalizing_mask = torch.Tensor([[float('-inf') if token == 0 else 0 for token in entry] for entry in mask]).to(device)\n",
        "    return torch.nn.functional.softmax(batch + normalizing_mask, dim=-1)\n",
        "\n",
        "def padd_mask(batch):\n",
        "    return torch.Tensor([[0 if token == 0 else 1 for token in entry] for entry in batch]).to(device)\n",
        "\n",
        "def collate_fn_padd(batch):\n",
        "  '''\n",
        "  We add padding to our minibatches and create tensors for our model\n",
        "  '''\n",
        "  batch_labels = [l for f, l in batch]\n",
        "  batch_features = [f for f, l in batch]\n",
        "  batch_features_len = [len(f) for f, l in batch]\n",
        "  seq_tensor = torch.zeros((len(batch), max(batch_features_len))).long()\n",
        "\n",
        "  for idx, (seq, seqlen) in enumerate(zip(batch_features, batch_features_len)):\n",
        "    seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
        "\n",
        "  batch_labels = torch.FloatTensor(batch_labels)\n",
        "  return seq_tensor, batch_labels\n",
        "\n",
        "class Task1Dataset(Dataset):\n",
        "  def __init__(self, train_data, labels):\n",
        "    self.x_train = train_data\n",
        "    self.y_train = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y_train)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    return self.x_train[item], self.y_train[item]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6I-3E_ev3sd"
      },
      "source": [
        "def encode_edited(edited_sentence, grades, tokenizer, pad_len=None):\r\n",
        "  pad_len = max([len(i) for i in edited_sentence]) if pad_len is None else pad_len\r\n",
        "  encoded_data = []\r\n",
        "  attention_data = []\r\n",
        "\r\n",
        "  for sentence in edited_sentence:\r\n",
        "    encoded = tokenizer.encode_plus(sentence, padding='max_length', max_length=pad_len, return_tensors='pt')\r\n",
        "    encoded_data.append(encoded['input_ids'])\r\n",
        "\r\n",
        "  # Split train dataset to train and validation sets\r\n",
        "  train_data = torch.cat(encoded_data).to(device)\r\n",
        "  encoded_grades  = torch.tensor(grades).to(device)\r\n",
        "\r\n",
        "  train_val_dataset = TensorDataset(train_data, encoded_grades)\r\n",
        "\r\n",
        "  num_train = round(len(train_val_dataset) * train_proportion)\r\n",
        "  num_val = len(train_val_dataset) - num_train\r\n",
        "  train_dataset, val_dataset = random_split(train_val_dataset, (num_train, num_val))\r\n",
        "\r\n",
        "  # Create dataloaders from the tokenised embeddings\r\n",
        "  train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\r\n",
        "  val_dataloader = DataLoader(val_dataset, sampler=RandomSampler(val_dataset), batch_size=batch_size)\r\n",
        "\r\n",
        "  return train_dataloader, val_dataloader\r\n",
        "\r\n",
        "def encode_both(og_sentence, edited_sentence, grades, tokenizer, with_attention=False, pad_len=None):\r\n",
        "  pad_len = max([len(i) for i in edited_sentence]) if pad_len is None else pad_len\r\n",
        "  encoded_data = []\r\n",
        "  attention_data = []\r\n",
        "\r\n",
        "  for og, new in zip(og_sentence, edited_sentence):\r\n",
        "    encoded = tokenizer.encode_plus(og, text_pair=new, padding='max_length', max_length=pad_len, return_tensors='pt')\r\n",
        "    encoded_data.append(encoded['input_ids'])\r\n",
        "\r\n",
        "    if with_attention:\r\n",
        "      attention_data.append(encoded['attention_mask'])\r\n",
        "\r\n",
        "  # Split train dataset to train and validation sets\r\n",
        "  train_data = torch.cat(encoded_data).to(device)\r\n",
        "  encoded_grades  = torch.tensor(grades).to(device)\r\n",
        "\r\n",
        "  if with_attention:\r\n",
        "    attention_data = torch.cat(attention_data).to(device)\r\n",
        "    train_val_dataset = TensorDataset(train_data, attention_data, encoded_grades)\r\n",
        "  else:\r\n",
        "    train_val_dataset = TensorDataset(train_data, encoded_grades)\r\n",
        "\r\n",
        "  num_train = round(len(train_val_dataset) * train_proportion)\r\n",
        "  num_val = len(train_val_dataset) - num_train\r\n",
        "  train_dataset, val_dataset = random_split(train_val_dataset, (num_train, num_val))\r\n",
        "\r\n",
        "  # Create dataloaders from the tokenised embeddings\r\n",
        "  train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\r\n",
        "  val_dataloader = DataLoader(val_dataset, sampler=RandomSampler(val_dataset), batch_size=batch_size)\r\n",
        "\r\n",
        "  return train_dataloader, val_dataloader"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdC_r9kcbqnZ"
      },
      "source": [
        "# Models\r\n",
        "\r\n",
        "Below are the model architectures that was at some point part of the testing of the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9nQpept3BQg"
      },
      "source": [
        "# Skeleton BiLSTM model\n",
        "class BiLSTM(nn.Module):\n",
        "  def __init__(self, embedding_dim, hidden_dim, vocab_size, batch_size, device):\n",
        "    super(BiLSTM, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.device = device\n",
        "    self.batch_size = batch_size\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "    # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "    # with dimensionality hidden_dim.\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
        "\n",
        "    # The linear layer that maps from hidden state space to tag space\n",
        "    self.hidden2label = nn.Linear(hidden_dim * 2, 1)\n",
        "    self.hidden = self.init_hidden()\n",
        "\n",
        "  def init_hidden(self):\n",
        "    # Before we've done anything, we dont have any hidden state.\n",
        "    # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\n",
        "    # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
        "    return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device), \\\n",
        "            torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\n",
        "\n",
        "  def forward(self, sentence):\n",
        "    embedded = self.embedding(sentence)\n",
        "    embedded = embedded.permute(1, 0, 2)\n",
        "\n",
        "    lstm_out, self.hidden = self.lstm(\n",
        "        embedded.view(len(embedded), self.batch_size, self.embedding_dim), self.hidden)\n",
        "\n",
        "    out = self.hidden2label(lstm_out[-1])\n",
        "    return out"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaRo-Ma1b62N"
      },
      "source": [
        "# RoBERTa\r\n",
        "class RoBERTa(nn.Module):\r\n",
        "  def __init__(self, embedding_dim, hidden_dim, batch_size, device, roberta_pretrained='roberta-base'):\r\n",
        "    super(RoBERTa, self).__init__()\r\n",
        "    self.hidden_dim = hidden_dim\r\n",
        "    self.embedding_dim = embedding_dim\r\n",
        "    self.device = device\r\n",
        "    self.batch_size = batch_size\r\n",
        "    self.roberta = model = RobertaModel.from_pretrained(roberta_pretrained)\r\n",
        "\r\n",
        "    # The LSTM takes word embeddings as inputs, and outputs hidden states with hidden_dim dimensions\r\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\r\n",
        "    self.hidden2label = nn.Linear(hidden_dim * 2, 1)\r\n",
        "    self.hidden = self.init_hidden()\r\n",
        "\r\n",
        "  def init_hidden(self):\r\n",
        "    # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\r\n",
        "    return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device), \\\r\n",
        "            torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\r\n",
        "\r\n",
        "  def get_embedded(self, sentence):\r\n",
        "    # Returns last hidden layer and pooled output (Linear & tanh) (we're only interested in the hidden layer)\r\n",
        "    outputs = self.roberta(sentence)\r\n",
        "    last_hidden_states = outputs[0]\r\n",
        "    return last_hidden_states\r\n",
        "\r\n",
        "  def forward(self, sentence):\r\n",
        "    embedded = self.get_embedded(sentence)\r\n",
        "\r\n",
        "    # Do I still need this if I'm also training the BERT model?\r\n",
        "    lstm_out, self.hidden = self.lstm(embedded, self.hidden)\r\n",
        "    \r\n",
        "    out = self.hidden2label(lstm_out[-1])\r\n",
        "    return out"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z94C03CgV7h"
      },
      "source": [
        "# Bert\r\n",
        "class BERT(nn.Module):\r\n",
        "  def __init__(self, embedding_dim, hidden_dim, \r\n",
        "                batch_size, device, bert_model=None, bert_pretrained='bert-base-uncased'):\r\n",
        "    super(BERT, self).__init__()\r\n",
        "    self.hidden_dim = hidden_dim\r\n",
        "    self.embedding_dim = embedding_dim\r\n",
        "    self.device = device\r\n",
        "    self.batch_size = batch_size\r\n",
        "    self.bert = BertModel.from_pretrained(bert_pretrained) if bert_model is None else bert_model\r\n",
        "\r\n",
        "    # The LSTM takes word embeddings as inputs, and outputs hidden states with hidden_dim dimensions\r\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\r\n",
        "    self.hidden2label = nn.Linear(hidden_dim * 2, 1)\r\n",
        "    self.hidden = self.init_hidden()\r\n",
        "\r\n",
        "    # Attention Layer?\r\n",
        "    self.attn_linear = nn.Linear(hidden_dim * 2, 1)\r\n",
        "\r\n",
        "  def init_hidden(self):\r\n",
        "    # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\r\n",
        "    return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device), \\\r\n",
        "            torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\r\n",
        "\r\n",
        "  def get_embedded(self, sentence, grad=False):\r\n",
        "    mask = padd_mask(sentence) # Get the attention mask for BERT\r\n",
        "\r\n",
        "    # Run the text through BERT, and collect all of the hidden states produced from all 12 layers\r\n",
        "    if grad:\r\n",
        "      last_hidden_states = self.bert(sentence, mask)[0] # The last hidden-state is the first element of the output tuple\r\n",
        "    else:\r\n",
        "      with torch.no_grad():\r\n",
        "        last_hidden_states = self.bert(sentence, mask)[0]\r\n",
        "\r\n",
        "    return last_hidden_states\r\n",
        "\r\n",
        "  def forward(self, sentence):\r\n",
        "    # Get word embeddings. BERT base gives us 768 hidden parameters for each word.\r\n",
        "    embedded = self.get_embedded(sentence) # (batch_size, max_len)\r\n",
        "\r\n",
        "    # (max_len, batch_size, 768) -> (batch_size, max_len, directions * hidden_dim)\r\n",
        "    lstm_out, self.hidden = self.lstm(embedded, self.hidden)\r\n",
        "\r\n",
        "    # Attention Mechanism\r\n",
        "    # Get similarity using DOT attention (i think)\r\n",
        "    # (batch_size, max_len, directions * hidden_dim) -> (batch_size, max_len)\r\n",
        "    att_out = self.attn_linear(lstm_out).squeeze(-1)\r\n",
        "    # Get the attention weights for each token in a sentence (batch_size)\r\n",
        "    # (batch_size, max_len) -> (batch_size, max_len)\r\n",
        "    # att_out = torch.nn.functional.softmax(att_out, dim=-1)\r\n",
        "    att_out = softmax_mask(att_out, mask)\r\n",
        "    # Get sentence vector which is a weighted sum of token hidden states\r\n",
        "    # (batch_size, max_len) -> (batch_size, directions * hidden_dim)\r\n",
        "    att_out = torch.sum(att_out.unsqueeze(-1) * lstm_out, dim=1)\r\n",
        "    \r\n",
        "    # out = self.hidden2label(lstm_out[-1])\r\n",
        "    out = self.hidden2label(att_out)\r\n",
        "    return out"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnJse9uFu8UH"
      },
      "source": [
        "# Initialisation + Preprocessing\r\n",
        "Prepare the data for training, assign hyperparameters, initialise the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNTcGaIaJ63d"
      },
      "source": [
        "# Hyperparameters\r\n",
        "bert_type = 'bert-base-uncased'\r\n",
        "rob_type  = 'roberta-base'\r\n",
        "pad_len = 64\r\n",
        "\r\n",
        "e_dim = 768\r\n",
        "h_dim = 50\r\n",
        "\r\n",
        "batch_size = 32\r\n",
        "train_proportion = 0.8"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPzQbQazzoey"
      },
      "source": [
        "# We set our training data and test data\r\n",
        "training_data = train_df\r\n",
        "test_data = test_df\r\n",
        "\r\n",
        "# Parse training and test data to tuple of original sentences, new sentences, etc.\r\n",
        "x_og, x_new, _, _ = get_sentences(training_data)\r\n",
        "y_og, y_new, _, _ = get_sentences(test_data)\r\n",
        "x_grades = train_df['meanGrade']\r\n",
        "\r\n",
        "# Get Tokenizer for preprocessing\r\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(bert_type, do_lower_case=True)\r\n",
        "rob_tokenizer = RobertaTokenizer.from_pretrained(rob_type)\r\n",
        "\r\n",
        "# Get the dataloaders\r\n",
        "bert_single_train_loader, bert_single_val_loader = encode_edited(x_new, x_grades, bert_tokenizer)\r\n",
        "bert_both_train_loader, bert_both_val_loader = encode_both(x_og, x_new, x_grades, bert_tokenizer)\r\n",
        "robert_single_train_loader, robert_single_val_loader = encode_edited(x_new, x_grades, rob_tokenizer)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ops2yqW1w1A"
      },
      "source": [
        "# Glove embedding based data loading\r\n",
        "# Creating word vectors\r\n",
        "training_vocab, training_tokenized_corpus = create_vocab(training_data)\r\n",
        "test_vocab, test_tokenized_corpus = create_vocab(test_data)\r\n",
        "\r\n",
        "# Creating joint vocab from test and train:\r\n",
        "joint_vocab, joint_tokenized_corpus = create_vocab(pd.concat([training_data, test_data]))\r\n",
        "\r\n",
        "# We create representations for our tokens\r\n",
        "wvecs = [] # word vectors\r\n",
        "word2idx = [] # word2index\r\n",
        "idx2word = []\r\n",
        "\r\n",
        "# This is a large file, it will take a while to load in the memory!\r\n",
        "with codecs.open('glove.6B.100d.txt', 'r','utf-8') as f:\r\n",
        "  index = 1\r\n",
        "  for line in f.readlines():\r\n",
        "    # Ignore the first line - first line typically contains vocab, dimensionality\r\n",
        "    if len(line.strip().split()) > 3:\r\n",
        "      word = line.strip().split()[0]\r\n",
        "      if word in joint_vocab:\r\n",
        "          (word, vec) = (word,\r\n",
        "                     list(map(float,line.strip().split()[1:])))\r\n",
        "          wvecs.append(vec)\r\n",
        "          word2idx.append((word, index))\r\n",
        "          idx2word.append((index, word))\r\n",
        "          index += 1\r\n",
        "\r\n",
        "wvecs = np.array(wvecs)\r\n",
        "word2idx = dict(word2idx)\r\n",
        "idx2word = dict(idx2word)\r\n",
        "\r\n",
        "INPUT_DIM = len(word2idx)\r\n",
        "vectorized_seqs = [[word2idx[tok] for tok in seq if tok in word2idx] for seq in training_tokenized_corpus]\r\n",
        "\r\n",
        "# To avoid any sentences being empty (if no words match to our word embeddings)\r\n",
        "feature = [x if len(x) > 0 else [0] for x in vectorized_seqs]\r\n",
        "\r\n",
        "# 'feature' is a list of lists, each containing embedding IDs for word tokens\r\n",
        "train_and_dev = Task1Dataset(feature, train_df['meanGrade'])\r\n",
        "\r\n",
        "train_examples = round(len(train_and_dev)*train_proportion)\r\n",
        "dev_examples = len(train_and_dev) - train_examples\r\n",
        "\r\n",
        "train_dataset, dev_dataset = random_split(train_and_dev, (train_examples, dev_examples))\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\r\n",
        "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kDkb9QWvIlq"
      },
      "source": [
        "# Training\r\n",
        "Initialise optimisers and start training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "hDRPb2lEwsOr",
        "outputId": "05507198-bd2f-4493-8324-16690cce3591"
      },
      "source": [
        "## Bert Training\r\n",
        "#=====================================#\r\n",
        "# Define run specific hyperparameters #\r\n",
        "#=====================================#\r\n",
        "lr = 2e-5\r\n",
        "epochs = 4\r\n",
        "#=====================================#\r\n",
        "# Load Pretrained Bert model for double sequence training\r\n",
        "bert_double_pretrained = BertForSequenceClassification.from_pretrained(\r\n",
        "    bert_type, \r\n",
        "    num_labels = 1, # Regression model\r\n",
        ")\r\n",
        "bert_double_pretrained.to(device) # Move to cuda if possible\r\n",
        "bert_double_pretrained.double() # Convert classifier to regressor\r\n",
        "# Initialise full model\r\n",
        "model = BERT(e_dim, h_dim, batch_size, device, bert_double_pretrained)\r\n",
        "\r\n",
        "# Use the bert double loaders\r\n",
        "train_loader = bert_both_train_loader\r\n",
        "dev_loader = bert_both_val_loader\r\n",
        "\r\n",
        "# Optimizer and Scheduler setup\r\n",
        "optimizer = AdamW(model.parameters(), lr=lr)\r\n",
        "scheduler = get_linear_schedule_with_warmup(\r\n",
        "    optimizer, \r\n",
        "    num_warmup_steps=0, \r\n",
        "    num_training_steps=(epochs * len(train_loader))\r\n",
        ")\r\n",
        "\r\n",
        "print(\"Model initialised.\")\r\n",
        "\r\n",
        "# Define the loss function\r\n",
        "loss_fn = nn.MSELoss()\r\n",
        "loss_fn = loss_fn.to(device)\r\n",
        "\r\n",
        "print(\"Model initialised.\")\r\n",
        "train(train_loader, dev_loader, model, epochs, loss_fn)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model initialised.\n",
            "Model initialised.\n",
            "Training model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-523a65db79c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model initialised.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-5fae0c02cfab>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_iter, dev_iter, model, number_epoch, loss_fn)\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-0dfbb5b5c87c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0;31m# (max_len, batch_size, 768) -> (batch_size, max_len, directions * hidden_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m       \u001b[0;31m# Attention Mechanism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    174\u001b[0m             raise RuntimeError(\n\u001b[1;32m    175\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[0;32m--> 176\u001b[0;31m                     expected_input_dim, input.dim()))\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "0_4Benjk3BQg",
        "outputId": "706b17d3-b5a1-4f00-c689-f7927e12aa66"
      },
      "source": [
        "##Â Approach 1 code, using functions defined above:\n",
        "\n",
        "#=====================================#\n",
        "# Define run specific hyperparameters #\n",
        "#=====================================#\n",
        "lr = 0.001\n",
        "epochs = 6\n",
        "#=====================================#\n",
        "\n",
        "model = BiLSTM(e_dim, h_dim, INPUT_DIM, batch_size, device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "model.to(device)\n",
        "\n",
        "# We provide the model with our embeddings\n",
        "model.embedding.weight.data.copy_(torch.from_numpy(wvecs))\n",
        "\n",
        "# Define the loss function\n",
        "loss_fn = nn.MSELoss()\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "print(\"Model initialised.\")\n",
        "train(train_loader, dev_loader, model, epochs, loss_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab created.\n",
            "Model initialised.\n",
            "Dataloaders created.\n",
            "Training model.\n",
            "| Epoch: 01 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
            "| Epoch: 02 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
            "| Epoch: 03 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
            "| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
            "| Epoch: 05 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
            "| Epoch: 06 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
            "| Epoch: 07 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.38 | Val. MSE: 0.38 |  Val. RMSE: 0.62 |\n",
            "| Epoch: 08 | Train Loss: 0.24 | Train MSE: 0.24 | Train RMSE: 0.49 |         Val. Loss: 0.37 | Val. MSE: 0.37 |  Val. RMSE: 0.61 |\n",
            "| Epoch: 09 | Train Loss: 0.23 | Train MSE: 0.23 | Train RMSE: 0.48 |         Val. Loss: 0.38 | Val. MSE: 0.38 |  Val. RMSE: 0.62 |\n",
            "| Epoch: 10 | Train Loss: 0.22 | Train MSE: 0.22 | Train RMSE: 0.47 |         Val. Loss: 0.39 | Val. MSE: 0.39 |  Val. RMSE: 0.63 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB0zCYH11jJp"
      },
      "source": [
        "## Roberta Training\r\n",
        "#=====================================#\r\n",
        "# Define run specific hyperparameters #\r\n",
        "#=====================================#\r\n",
        "lr = 0.001\r\n",
        "epochs = 3\r\n",
        "#=====================================#\r\n",
        "vectorized_seqs = [tokenizer.encode(sentence) for sentence in training_data]\r\n",
        "# input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\")).unsqueeze(0)  # Batch size 1\r\n",
        "\r\n",
        "model = RoBERTa(EMBEDDING_DIM, 50, BATCH_SIZE, device)\r\n",
        "model.to(device)\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters())\r\n",
        "\r\n",
        "print(\"Model initialised.\")\r\n",
        "\r\n",
        "train_loader = robert_single_train_loader\r\n",
        "dev_loader = robert_single_val_loader\r\n",
        "\r\n",
        "# Define the loss function\r\n",
        "loss_fn = nn.MSELoss()\r\n",
        "loss_fn = loss_fn.to(device)\r\n",
        "\r\n",
        "print(\"Model initialised.\")\r\n",
        "train(train_loader, dev_loader, model, epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahuFb8KU3BQi"
      },
      "source": [
        "#### Approach 2: No pre-trained representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewkWUrP33BQj",
        "outputId": "1539c4f1-4122-41ea-b299-f4c91a1c6b65"
      },
      "source": [
        "train_and_dev = train_df['edit']\n",
        "\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(train_df['edit'], train_df['meanGrade'],\n",
        "                                                                        test_size=(1-train_proportion),\n",
        "                                                                        random_state=42)\n",
        "\n",
        "# We train a Tf-idf model\n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "train_counts = count_vect.fit_transform(training_data)\n",
        "transformer = TfidfTransformer().fit(train_counts)\n",
        "train_counts = transformer.transform(train_counts)\n",
        "regression_model = LinearRegression().fit(train_counts, training_y)\n",
        "\n",
        "# Train predictions\n",
        "predicted_train = regression_model.predict(train_counts)\n",
        "\n",
        "# Calculate Tf-idf using train and dev, and validate model on dev:\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\n",
        "\n",
        "test_counts = count_vect.transform(dev_data)\n",
        "\n",
        "test_counts = transformer.transform(test_counts)\n",
        "\n",
        "# Dev predictions\n",
        "predicted = regression_model.predict(test_counts)\n",
        "\n",
        "# We run the evaluation:\n",
        "print(\"\\nTrain performance:\")\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\n",
        "\n",
        "print(\"\\nDev performance:\")\n",
        "sse, mse = model_performance(predicted, dev_y, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train performance:\n",
            "| MSE: 0.13 | RMSE: 0.37 |\n",
            "\n",
            "Dev performance:\n",
            "| MSE: 0.36 | RMSE: 0.60 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA5bYyuG3BQj"
      },
      "source": [
        "#### Baseline for task 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72fIC0-I3BQk",
        "outputId": "d01b6da1-0c83-4f30-cdcc-a18c4c21798c"
      },
      "source": [
        "#Â Baseline for the task\n",
        "pred_baseline = torch.zeros(len(dev_y)) + np.mean(training_y)\n",
        "print(\"\\nBaseline performance:\")\n",
        "sse, mse = model_performance(pred_baseline, dev_y, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Baseline performance:\n",
            "| MSE: 0.34 | RMSE: 0.58 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz1VVAIG0hyv"
      },
      "source": [
        "# Deprecated Code\r\n",
        "\r\n",
        "Kept temporarily until the devs are ready to delete forever :D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDHlDBubKC9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "e47c611966844eadb2cfe926673e494e",
            "47c919f5b011483d8b602ba956990374",
            "671f316ee5f2465eaf5267a1976b24e8",
            "d5b7596f16804eeb8f8dd3b1073a06be",
            "98c6870f0bc449b39f9d8653aa8d27cd",
            "8ac8e41d5b5f4ebb86a4531f549c435b",
            "333167d4cc56449fa4869d2122c09135",
            "78629d0ac788406b9c48e0074556096c"
          ]
        },
        "outputId": "a9187c47-e01f-4435-ae1c-46e216552a22"
      },
      "source": [
        "# We set our training data and test data\r\n",
        "training_data = train_df\r\n",
        "test_data = test_df\r\n",
        "\r\n",
        "# Parse training and test data to tuple of original sentences, new sentences, etc.\r\n",
        "x_og, x_new, _, _ = get_sentences(training_data)\r\n",
        "y_og, y_new, _, _ = get_sentences(test_data)\r\n",
        "\r\n",
        "# Bert Preprocessing\r\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_type, do_lower_case=True)\r\n",
        "\r\n",
        "# Tokenise sentences and add special Bert tokens as necessary\r\n",
        "train_input = []\r\n",
        "train_masks = []\r\n",
        "test_input  = []\r\n",
        "test_masks  = []\r\n",
        "train_grades = train_df['meanGrade']\r\n",
        "for og, new in zip(x_og, x_new):\r\n",
        "  encoded_plus = tokenizer.encode_plus(og, text_pair=new, max_length=pad_len, \r\n",
        "                                       truncation=True, padding='max_length', return_tensors='pt')\r\n",
        "  train_input.append(encoded_plus['input_ids'])\r\n",
        "  train_masks.append(encoded_plus['attention_mask'])\r\n",
        "\r\n",
        "# Tokenise Test set\r\n",
        "for og, new in zip(y_og, y_new):\r\n",
        "  encoded_plus = tokenizer.encode_plus(og, text_pair=new, max_length=pad_len, \r\n",
        "                                       truncation=True, padding='max_length', return_tensors='pt')\r\n",
        "  test_input.append(encoded_plus['input_ids'])\r\n",
        "  test_masks.append(encoded_plus['attention_mask'])\r\n",
        "\r\n",
        "# Convert to Tensors\r\n",
        "train_input = torch.cat(train_input)\r\n",
        "train_masks = torch.cat(train_masks)\r\n",
        "train_grades = torch.tensor(train_grades)\r\n",
        "test_input  = torch.cat(test_input)\r\n",
        "test_masks  = torch.cat(test_masks)\r\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e47c611966844eadb2cfe926673e494e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS4IYQ8Tq7x9"
      },
      "source": [
        "# Split train dataset to train and validation sets\r\n",
        "train_val_dataset = TensorDataset(train_input, train_masks, train_grades)\r\n",
        "num_train = round(len(train_val_dataset) * train_proportion)\r\n",
        "num_val = len(train_val_dataset) - num_train\r\n",
        "train_dataset, val_dataset = random_split(train_val_dataset, (num_train, num_val))\r\n",
        "\r\n",
        "# Create dataloaders from the tokenised embeddings\r\n",
        "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\r\n",
        "val_dataloader = DataLoader(val_dataset, sampler=RandomSampler(val_dataset), batch_size=batch_size)"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}