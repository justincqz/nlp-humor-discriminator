{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Copy of Copy of task_1_main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3614f8e8c18148a8939cb25058758565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1a2ecc0a67a74b1c8b320968c3d84e1b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f8a6b24ea46c43bdb9d74580f88a3b04",
              "IPY_MODEL_b9dff5ecadd44ef1b41e77ce6b8e2de0"
            ]
          }
        },
        "1a2ecc0a67a74b1c8b320968c3d84e1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8a6b24ea46c43bdb9d74580f88a3b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ebee2130adad45fe987ed52c09166881",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce618fb2c58e469daf83a850c7ae4f8b"
          }
        },
        "b9dff5ecadd44ef1b41e77ce6b8e2de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e3dc9d911c24a9c831c68bee4e16bb1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 804kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99e04808bd204b67ac4d1e983fb43895"
          }
        },
        "ebee2130adad45fe987ed52c09166881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce618fb2c58e469daf83a850c7ae4f8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e3dc9d911c24a9c831c68bee4e16bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99e04808bd204b67ac4d1e983fb43895": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0464f16188664658b30e1d0eec4b5275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_23efa5c1c4f84bde95257bf219b2bf50",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6726c8241a5a488e8fb00655b8e4f47a",
              "IPY_MODEL_3e184066d3864aaf8b8ad2abd46952e7"
            ]
          }
        },
        "23efa5c1c4f84bde95257bf219b2bf50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6726c8241a5a488e8fb00655b8e4f47a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ce858215b5b64e6bbc5038fea1dd2208",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b21db000c9b491e9bb1f30881864636"
          }
        },
        "3e184066d3864aaf8b8ad2abd46952e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d985dd81efee4ddb996fb166c6fba6b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:01&lt;00:00, 762kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0861de5b75042df8b04b1ff4d917fa5"
          }
        },
        "ce858215b5b64e6bbc5038fea1dd2208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b21db000c9b491e9bb1f30881864636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d985dd81efee4ddb996fb166c6fba6b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0861de5b75042df8b04b1ff4d917fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4fbd2522aed425797c6351009a1fb56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_db4d6c1f40e44815b1c9ebaa82249781",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_08f799298f03483bba9f352da93aef60",
              "IPY_MODEL_0023d6bf3cd44d1bbdf02a4623901912"
            ]
          }
        },
        "db4d6c1f40e44815b1c9ebaa82249781": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08f799298f03483bba9f352da93aef60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e85f787243324846a9bf07ebc46bf1e4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7d1a0c59a78423688b2ab2220b03613"
          }
        },
        "0023d6bf3cd44d1bbdf02a4623901912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0a3a3db0cdbb42fb82b53c6f4d792ee7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 1.25MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4776cab386e54cfa84f369d069175dd4"
          }
        },
        "e85f787243324846a9bf07ebc46bf1e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7d1a0c59a78423688b2ab2220b03613": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a3a3db0cdbb42fb82b53c6f4d792ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4776cab386e54cfa84f369d069175dd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a903ccb05eb41ada7eee57ff792bbd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0040b42986824244ab8f29a166b8305e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ca0a8306bd5c415d9108077e4f42a210",
              "IPY_MODEL_2ba5775923244a1d8c187fd9980e972a"
            ]
          }
        },
        "0040b42986824244ab8f29a166b8305e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca0a8306bd5c415d9108077e4f42a210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_90746e70e30c44a48dd9f425458a0a12",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d4031ca2a264da094f1cfc7e74a9808"
          }
        },
        "2ba5775923244a1d8c187fd9980e972a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d023217d896f413e888db8c697d53d3f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:22&lt;00:00, 19.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f36a3f7d3f8498986e429d2c1eaecfb"
          }
        },
        "90746e70e30c44a48dd9f425458a0a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d4031ca2a264da094f1cfc7e74a9808": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d023217d896f413e888db8c697d53d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f36a3f7d3f8498986e429d2c1eaecfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "475a166de2ff4f57b022c95156d6754b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3774b4101cec42f5baa8258f81dc7ecb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_da28d0b8e64942a7b95bbe43f8a27544",
              "IPY_MODEL_b10833ac40af4a6294bd67a6a0acbd5e"
            ]
          }
        },
        "3774b4101cec42f5baa8258f81dc7ecb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da28d0b8e64942a7b95bbe43f8a27544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9f31c87469c4470980b03a146441a6aa",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b682d41ebb4e4aa4b41b86c4629d7b50"
          }
        },
        "b10833ac40af4a6294bd67a6a0acbd5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_292a17e6306f4b92b5f7b73f486c2499",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 68.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38ca5ec4ffa149c0ba9836625dd56da8"
          }
        },
        "9f31c87469c4470980b03a146441a6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b682d41ebb4e4aa4b41b86c4629d7b50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "292a17e6306f4b92b5f7b73f486c2499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38ca5ec4ffa149c0ba9836625dd56da8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95590144ed2144a699da65e24e68f457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_867559c9d5cc429d835e22751bd4bddb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_40de6f177ff64acaa92107a74e5eb480",
              "IPY_MODEL_32862ea5d74447eaa97e562bf41fe317"
            ]
          }
        },
        "867559c9d5cc429d835e22751bd4bddb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40de6f177ff64acaa92107a74e5eb480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_124858509fb4499ca63bd08ae27f407d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea23f0c0a50444b6821b8412df69d9ec"
          }
        },
        "32862ea5d74447eaa97e562bf41fe317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_716f38b2eed34f76af22e157adfbd555",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:10&lt;00:00, 42.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71a0d170505b488b898184713a785208"
          }
        },
        "124858509fb4499ca63bd08ae27f407d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea23f0c0a50444b6821b8412df69d9ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "716f38b2eed34f76af22e157adfbd555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71a0d170505b488b898184713a785208": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46d3be4a21434e119f96958201a9df89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32fc129b75bd46bdbbc54072ba887f40",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_11aceda189ec44619162f061175875e7",
              "IPY_MODEL_128f99a2a63d45038d654049a108504a"
            ]
          }
        },
        "32fc129b75bd46bdbbc54072ba887f40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11aceda189ec44619162f061175875e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f0dde8b70c6946a39737400f5da469aa",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94d947d7795146f58727f04d57d4f5d1"
          }
        },
        "128f99a2a63d45038d654049a108504a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e21021c22d854d83a2f939f113789813",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 45.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45e2b02e8f274b2d92e97d712118acc7"
          }
        },
        "f0dde8b70c6946a39737400f5da469aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94d947d7795146f58727f04d57d4f5d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e21021c22d854d83a2f939f113789813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45e2b02e8f274b2d92e97d712118acc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e47c611966844eadb2cfe926673e494e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_47c919f5b011483d8b602ba956990374",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_671f316ee5f2465eaf5267a1976b24e8",
              "IPY_MODEL_d5b7596f16804eeb8f8dd3b1073a06be"
            ]
          }
        },
        "47c919f5b011483d8b602ba956990374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "671f316ee5f2465eaf5267a1976b24e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_98c6870f0bc449b39f9d8653aa8d27cd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ac8e41d5b5f4ebb86a4531f549c435b"
          }
        },
        "d5b7596f16804eeb8f8dd3b1073a06be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_333167d4cc56449fa4869d2122c09135",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 807kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_78629d0ac788406b9c48e0074556096c"
          }
        },
        "98c6870f0bc449b39f9d8653aa8d27cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ac8e41d5b5f4ebb86a4531f549c435b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "333167d4cc56449fa4869d2122c09135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "78629d0ac788406b9c48e0074556096c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWRt9UuE3BQP"
      },
      "source": [
        "### Coursework coding instructions (please also see full coursework spec)\n",
        "\n",
        "Please choose if you want to do either Task 1 or Task 2. You should write your report about one task only.\n",
        "\n",
        "For the task you choose you will need to do two approaches:\n",
        "  - Approach 1, which can use use pre-trained embeddings / models\n",
        "  - Approach 2, which should not use any pre-trained embeddings or models\n",
        "We should be able to run both approaches from the same colab file\n",
        "\n",
        "#### Running your code:\n",
        "  - Your models should run automatically when running your colab file without further intervention\n",
        "  - For each task you should automatically output the performance of both models\n",
        "  - Your code should automatically download any libraries required\n",
        "\n",
        "#### Structure of your code:\n",
        "  - You are expected to use the 'train', 'eval' and 'model_performance' functions, although you may edit these as required\n",
        "  - Otherwise there are no restrictions on what you can do in your code\n",
        "\n",
        "#### Documentation:\n",
        "  - You are expected to produce a .README file summarising how you have approached both tasks\n",
        "\n",
        "#### Reproducibility:\n",
        "  - Your .README file should explain how to replicate the different experiments mentioned in your report\n",
        "\n",
        "Good luck! We are really looking forward to seeing your reports and your model code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQN7xeP23BQW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "575b38d8-d3d7-4bef-d65d-86a7187ebb20"
      },
      "source": [
        "# You will need to download any word embeddings required for your code, e.g.:\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-22 21:15:48--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-02-22 21:15:48--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-02-22 21:15:48--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip         30%[=====>              ] 252.01M  2.00MB/s    eta 4m 45s ^C\n",
            "Archive:  glove.6B.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of glove.6B.zip or\n",
            "        glove.6B.zip.zip, and cannot find glove.6B.zip.ZIP, period.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXHhn8ABipCS",
        "outputId": "b3de2efe-7c6c-4e0e-e600-2767f183f690"
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip install torch\r\n",
        "!pip install skorch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 48.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 54.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=5bd361bf08f1b56e82768066f553dfcac7f5f1ceb5654c9a40f9bf81c225df29\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.2\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Collecting skorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/c7/2f6434f9360c91a4bf14ae85f634758e5dacd3539cca4266a60be9f881ae/skorch-0.9.0-py3-none-any.whl (125kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.19.5)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.7)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.41.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (1.0.0)\n",
            "Installing collected packages: skorch\n",
            "Successfully installed skorch-0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL0-upkD3BQY"
      },
      "source": [
        "# Imports\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from transformers import BertTokenizer, RobertaTokenizer, AdamW, BertConfig\n",
        "from transformers import BertModel, BertForSequenceClassification,  RobertaModel\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import codecs\n",
        "import gc "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov0JGF5J3BQZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f85fec6-b7f9-4c1f-f8d8-fe51d592c713"
      },
      "source": [
        "# Setting random seed and device\n",
        "SEED = 1\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "np.random.seed(SEED)\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "if use_cuda:\n",
        "  print(\"Using GPU.\")\n",
        "else:\n",
        "  print(\"Using CPU.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oZQFbuF3BQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b65135b-aaec-4c0f-edfa-0096a3698285"
      },
      "source": [
        "# Load data\n",
        "\n",
        "!wget -O train.csv https://drive.google.com/u/0/uc?id=1UgrdjcHHZmAthjusQDAKoSqd37up-41f&export=download\n",
        "!wget -O dev.csv https://drive.google.com/u/0/uc?id=1rY6A0cN_cxAMK3aMHlTFWxhbcLFomvQL&export=download\n",
        "\n",
        "train_df = pd.read_csv('./train.csv')\n",
        "test_df = pd.read_csv('./dev.csv')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-23 13:59:31--  https://drive.google.com/u/0/uc?id=1UgrdjcHHZmAthjusQDAKoSqd37up-41f\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.197.139, 74.125.197.113, 74.125.197.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.197.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-00-cc-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/kru3gc9nhf4t9j9goqmgi405il3qvbfr/1614088725000/13802342090854404605/*/1UgrdjcHHZmAthjusQDAKoSqd37up-41f [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-02-23 13:59:32--  https://doc-00-cc-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/kru3gc9nhf4t9j9goqmgi405il3qvbfr/1614088725000/13802342090854404605/*/1UgrdjcHHZmAthjusQDAKoSqd37up-41f\n",
            "Resolving doc-00-cc-docs.googleusercontent.com (doc-00-cc-docs.googleusercontent.com)... 74.125.195.132, 2607:f8b0:400e:c09::84\n",
            "Connecting to doc-00-cc-docs.googleusercontent.com (doc-00-cc-docs.googleusercontent.com)|74.125.195.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 947914 (926K) [text/csv]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>] 925.70K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2021-02-23 13:59:32 (125 MB/s) - ‘train.csv’ saved [947914/947914]\n",
            "\n",
            "--2021-02-23 13:59:32--  https://drive.google.com/u/0/uc?id=1rY6A0cN_cxAMK3aMHlTFWxhbcLFomvQL\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.199.113, 74.125.199.102, 74.125.199.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.199.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0c-cc-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/gehmhiqaqvl00hgs7qtv725es5g6kmqh/1614088725000/13802342090854404605/*/1rY6A0cN_cxAMK3aMHlTFWxhbcLFomvQL [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-02-23 13:59:33--  https://doc-0c-cc-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/gehmhiqaqvl00hgs7qtv725es5g6kmqh/1614088725000/13802342090854404605/*/1rY6A0cN_cxAMK3aMHlTFWxhbcLFomvQL\n",
            "Resolving doc-0c-cc-docs.googleusercontent.com (doc-0c-cc-docs.googleusercontent.com)... 74.125.195.132, 2607:f8b0:400e:c09::84\n",
            "Connecting to doc-0c-cc-docs.googleusercontent.com (doc-0c-cc-docs.googleusercontent.com)|74.125.195.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 219349 (214K) [text/csv]\n",
            "Saving to: ‘dev.csv’\n",
            "\n",
            "dev.csv             100%[===================>] 214.21K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2021-02-23 13:59:33 (104 MB/s) - ‘dev.csv’ saved [219349/219349]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CylH-J33qTou"
      },
      "source": [
        "# Training and Evaluation Helpers\r\n",
        "Here we have the helper functions that define the training and evaluation cycle, with specialised functions for models which require inputs other than the traditional sentence + grade input (e.g. Bert)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TCwEEwS3BQd"
      },
      "source": [
        "# We define our training loop\n",
        "def train(train_iter, dev_iter, model, number_epoch, loss_fn):\n",
        "  \"\"\"\n",
        "  Training loop for the model, which calls on eval to evaluate after each epoch\n",
        "  \"\"\"\n",
        "  training_stats = []\n",
        "  print(\"Training model.\")\n",
        "\n",
        "  for epoch in range(1, number_epoch+1):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_sse = 0\n",
        "    no_observations = 0  # Observations used for training so far\n",
        "\n",
        "    for feature, target in train_iter:\n",
        "      # for RNN:\n",
        "      model.batch_size = target.shape[0]\n",
        "      no_observations = no_observations + target.shape[0]\n",
        "      model.hidden = model.init_hidden()\n",
        "\n",
        "      predictions = model(feature).squeeze(1)\n",
        "      optimizer.zero_grad()\n",
        "      loss = loss_fn(predictions, target)\n",
        "      sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy())\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()*target.shape[0]\n",
        "      epoch_sse += sse\n",
        "\n",
        "      loss = loss.detach().cpu().item()\n",
        "      del loss\n",
        "      gc.collect()\n",
        "\n",
        "    valid_loss, valid_mse, __, __ = eval(dev_iter, model)\n",
        "    epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
        "\n",
        "    print('| Epoch: %.2d | Train Loss: %.4f | Train RMSE: %.4f | Val. Loss: %.4f | Val. RMSE: %.4f |' % (\n",
        "      epoch, epoch_loss, epoch_mse**0.5, valid_loss, valid_mse**0.5\n",
        "    ))\n",
        "\n",
        "    training_stats.append({\n",
        "            'epoch': epoch,\n",
        "            'train_loss': epoch_loss,\n",
        "            'train_rmse': epoch_mse**0.5,\n",
        "            'val_loss': valid_loss,\n",
        "            'val_rmse': valid_mse**0.5\n",
        "    })\n",
        "\n",
        "  return training_stats"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI36r1_Z1eZ8"
      },
      "source": [
        "# Train function specifically for Bert models (includes attention mask and token types during forward)\r\n",
        "def train_bert(train_loader, val_loader, model, epochs):\r\n",
        "  \"\"\"\r\n",
        "  Training loop for the Bert model, which expects an additional attention mask as part of the data loaders.\r\n",
        "  \"\"\"\r\n",
        "  training_stats = []\r\n",
        "  print(\"Training model.\")\r\n",
        "\r\n",
        "  for epoch_i in range(epochs):\r\n",
        "    total_train_loss = 0\r\n",
        "    model.train()\r\n",
        "\r\n",
        "    x_pred = np.array([])\r\n",
        "    x_true = np.array([])\r\n",
        "\r\n",
        "    # Training Loop\r\n",
        "    for step, batch in enumerate(train_loader):\r\n",
        "      b_input_ids = batch[0].to(device)\r\n",
        "      b_labels = batch[1].to(device)\r\n",
        "\r\n",
        "      model.zero_grad()\r\n",
        "      out = model(b_input_ids, token_type_ids=None, attention_mask=((b_input_ids != 0).type(torch.long)), labels=b_labels)\r\n",
        "      loss = out.loss\r\n",
        "      logits = out.logits\r\n",
        "\r\n",
        "      total_train_loss += loss.item()\r\n",
        "      loss.backward()\r\n",
        "\r\n",
        "      loss = loss.detach().cpu().item()\r\n",
        "      del loss\r\n",
        "      gc.collect()\r\n",
        "\r\n",
        "      # Log predicted and true for MSE & RMSE\r\n",
        "      logits = logits.detach().cpu().numpy()\r\n",
        "      label_ids = b_labels.cpu().numpy()\r\n",
        "      x_pred = np.append(x_pred, logits)\r\n",
        "      x_true = np.append(x_true, label_ids)\r\n",
        "\r\n",
        "      # Clip the norm of the gradients to 1.0 to help prevent the \"exploding gradients\" problem\r\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "      optimizer.step()\r\n",
        "      scheduler.step() # Linear scheduler is based on steps rather than epochs\r\n",
        "\r\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\r\n",
        "    train_rmse = mean_squared_error(x_true, x_pred, squared=False)\r\n",
        "\r\n",
        "    # Validation \r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    # Tracking variables \r\n",
        "    total_eval_accuracy = 0\r\n",
        "    total_eval_loss = 0\r\n",
        "    nb_eval_steps = 0\r\n",
        "\r\n",
        "    y_pred = np.array([])\r\n",
        "    y_true = np.array([])\r\n",
        "\r\n",
        "    # Evaluate data for one epoch\r\n",
        "    for batch in val_loader:\r\n",
        "      b_input_ids = batch[0].to(device)\r\n",
        "      b_labels = batch[1].to(device)\r\n",
        "        \r\n",
        "      # Forward pass, calculate logit predictions\r\n",
        "      with torch.no_grad():        \r\n",
        "        out = model(b_input_ids, token_type_ids=None, attention_mask=((b_input_ids != 0).type(torch.long)), labels=b_labels)\r\n",
        "        out = out.cpu().detach()\r\n",
        "        loss = out.loss\r\n",
        "        logits = out.logits\r\n",
        "        total_eval_loss += loss.item()\r\n",
        "\r\n",
        "        loss = loss.detach().cpu().item()\r\n",
        "        del loss\r\n",
        "        gc.collect()\r\n",
        "\r\n",
        "        # Move logits and labels to CPU\r\n",
        "        logits = logits.detach().cpu().numpy()\r\n",
        "        label_ids = b_labels.cpu().numpy()\r\n",
        "        y_pred = np.append(y_pred,logits)\r\n",
        "        y_true = np.append(y_true,label_ids)\r\n",
        "        \r\n",
        "    val_rmse = mean_squared_error(y_true, y_pred, squared=False)\r\n",
        "    avg_val_loss = total_eval_loss / len(val_loader)\r\n",
        "    \r\n",
        "    print('| Epoch: %.2d | Train Loss: %.4f | Train RMSE: %.4f | Val. Loss: %.4f | Val. RMSE: %.4f |' % (\r\n",
        "          epoch_i + 1, avg_train_loss, train_rmse, avg_val_loss, val_rmse\r\n",
        "    ))\r\n",
        "\r\n",
        "    training_stats.append({\r\n",
        "            'epoch': epoch_i + 1,\r\n",
        "            'train_loss': avg_train_loss,\r\n",
        "            'train_rmse': train_rmse,\r\n",
        "            'val_loss': avg_val_loss,\r\n",
        "            'val_rmse.': val_rmse\r\n",
        "    })\r\n",
        "  return training_stats"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJeBxYW93BQd"
      },
      "source": [
        "# We evaluate performance on our dev set\n",
        "def eval(data_iter, model):\n",
        "  \"\"\"\n",
        "  Evaluating model performance on the dev set\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  epoch_sse = 0\n",
        "  pred_all = []\n",
        "  trg_all = []\n",
        "  no_observations = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in data_iter:\n",
        "      feature, target = batch\n",
        "      feature, target = feature.to(device), target.to(device)\n",
        "\n",
        "      # for RNN:\n",
        "      model.batch_size = target.shape[0]\n",
        "      no_observations = no_observations + target.shape[0]\n",
        "      model.hidden = model.init_hidden()\n",
        "\n",
        "      predictions = model(feature).squeeze(1)\n",
        "      loss = loss_fn(predictions, target)\n",
        "\n",
        "      # We get the mse\n",
        "      pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
        "      sse, __ = model_performance(pred, trg)\n",
        "\n",
        "      epoch_loss += loss.item()*target.shape[0]\n",
        "      epoch_sse += sse\n",
        "      pred_all.extend(pred)\n",
        "      trg_all.extend(trg)\n",
        "\n",
        "  return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO4PMTUl3BQd"
      },
      "source": [
        "# How we print the model performance\n",
        "def model_performance(output, target, print_output=False):\n",
        "  \"\"\"\n",
        "  Returns SSE and MSE per batch (printing the MSE and the RMSE)\n",
        "  \"\"\"\n",
        "  sq_error = (output - target)**2\n",
        "  sse = np.sum(sq_error)\n",
        "  mse = np.mean(sq_error)\n",
        "  rmse = np.sqrt(mse)\n",
        "\n",
        "  if print_output:\n",
        "    print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n",
        "\n",
        "  return sse, mse"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UWJ9Z96uay3"
      },
      "source": [
        "# Helper Functions\r\n",
        "\r\n",
        "Helper functions for preprocessing or during model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkYFRpHt3BQe"
      },
      "source": [
        "def create_vocab(data):\n",
        "  \"\"\"\n",
        "  Creating a corpus of all the tokens used\n",
        "  \"\"\"\n",
        "  tokenized_corpus = [] # Let us put the tokenized corpus in a list\n",
        "\n",
        "  for sentence in data:\n",
        "    tokenized_sentence = []\n",
        "\n",
        "    for token in sentence.split(' '): # simplest split is\n",
        "      tokenized_sentence.append(token)\n",
        "\n",
        "    tokenized_corpus.append(tokenized_sentence)\n",
        "\n",
        "  # Create single list of all vocabulary\n",
        "  vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
        "\n",
        "  for sentence in tokenized_corpus:\n",
        "    for token in sentence:\n",
        "      if token not in vocabulary:\n",
        "          vocabulary.append(token)\n",
        "\n",
        "  return vocabulary, tokenized_corpus"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu_7IziNqAPQ"
      },
      "source": [
        "def get_sentences(df, og_label='original', edit_label='edit'):\r\n",
        "  \"\"\"\r\n",
        "  Extract the original and new sentences + words from a dataframe\r\n",
        "  \"\"\"\r\n",
        "  p = r\"<(.*)\\/>\"\r\n",
        "  replace_regex = re.compile(p)\r\n",
        "  og_word = []\r\n",
        "  new_word = []\r\n",
        "  og_sentences = []\r\n",
        "  new_sentences = []\r\n",
        "\r\n",
        "  for s, w in df[[og_label, edit_label]].itertuples(index=False,name=None):\r\n",
        "    tokens = s.split(' ') # For each sentence get the words\r\n",
        "    m = replace_regex.search(str(s)) # Get the word to replace\r\n",
        "\r\n",
        "    assert not m is None # Couldn't regex match the replacement word\r\n",
        "\r\n",
        "    og_word.append(m.group(1))\r\n",
        "    new_word.append(w)\r\n",
        "    og_sentences.append(replace_regex.sub( m.group(1), s))\r\n",
        "    new_sentences.append(replace_regex.sub(w, s))\r\n",
        "  \r\n",
        "  return og_sentences, new_sentences, og_word, new_word\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_xUhSV43BQe"
      },
      "source": [
        "def softmax_mask(batch, mask):\n",
        "    normalizing_mask = torch.Tensor([[float('-inf') if token == 0 else 0 for token in entry] for entry in mask]).to(device)\n",
        "    return torch.nn.functional.softmax(batch + normalizing_mask, dim=-1)\n",
        "\n",
        "def padd_mask(batch):\n",
        "    return torch.Tensor([[0 if token == 0 else 1 for token in entry] for entry in batch]).to(device)\n",
        "\n",
        "def collate_fn_padd(batch):\n",
        "  '''\n",
        "  We add padding to our minibatches and create tensors for our model\n",
        "  '''\n",
        "  batch_labels = [l for f, l in batch]\n",
        "  batch_features = [f for f, l in batch]\n",
        "  batch_features_len = [len(f) for f, l in batch]\n",
        "  seq_tensor = torch.zeros((len(batch), max(batch_features_len))).long()\n",
        "\n",
        "  for idx, (seq, seqlen) in enumerate(zip(batch_features, batch_features_len)):\n",
        "    seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
        "\n",
        "  batch_labels = torch.FloatTensor(batch_labels)\n",
        "  return seq_tensor, batch_labels\n",
        "\n",
        "class Task1Dataset(Dataset):\n",
        "  def __init__(self, train_data, labels):\n",
        "    self.x_train = train_data\n",
        "    self.y_train = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y_train)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    return self.x_train[item], self.y_train[item]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6I-3E_ev3sd"
      },
      "source": [
        "def encode_edited(edited_sentence, grades, tokenizer, pad_len=None):\r\n",
        "  pad_len = max([len(i) for i in edited_sentence]) if pad_len is None else pad_len\r\n",
        "  encoded_data = []\r\n",
        "  attention_data = []\r\n",
        "\r\n",
        "  for sentence in edited_sentence:\r\n",
        "    encoded = tokenizer.encode_plus(sentence, padding='max_length', max_length=pad_len, return_tensors='pt')\r\n",
        "    encoded_data.append(encoded['input_ids'])\r\n",
        "\r\n",
        "  # Split train dataset to train and validation sets\r\n",
        "  train_data = torch.cat(encoded_data).to(device)\r\n",
        "  encoded_grades  = torch.FloatTensor(grades).to(device)\r\n",
        "\r\n",
        "  train_val_dataset = TensorDataset(train_data, encoded_grades)\r\n",
        "\r\n",
        "  num_train = round(len(train_val_dataset) * train_proportion)\r\n",
        "  num_val = len(train_val_dataset) - num_train\r\n",
        "  train_dataset, val_dataset = random_split(train_val_dataset, (num_train, num_val))\r\n",
        "\r\n",
        "  # Create dataloaders from the tokenised embeddings\r\n",
        "  train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\r\n",
        "  val_dataloader = DataLoader(val_dataset, sampler=RandomSampler(val_dataset), batch_size=batch_size)\r\n",
        "\r\n",
        "  return train_dataloader, val_dataloader\r\n",
        "\r\n",
        "def encode_both(og_sentence, edited_sentence, grades, tokenizer, with_attention=False, pad_len=None):\r\n",
        "  pad_len = max([len(i) for i in edited_sentence]) if pad_len is None else pad_len\r\n",
        "  encoded_data = []\r\n",
        "  attention_data = []\r\n",
        "\r\n",
        "  for og, new in zip(og_sentence, edited_sentence):\r\n",
        "    encoded = tokenizer.encode_plus(og, text_pair=new, padding='max_length', max_length=pad_len, return_tensors='pt')\r\n",
        "    encoded_data.append(encoded['input_ids'])\r\n",
        "\r\n",
        "    if with_attention:\r\n",
        "      attention_data.append(encoded['attention_mask'])\r\n",
        "\r\n",
        "  # Split train dataset to train and validation sets\r\n",
        "  train_data = torch.cat(encoded_data).to(device)\r\n",
        "  encoded_grades  = torch.FloatTensor(grades).to(device)\r\n",
        "\r\n",
        "  if with_attention:\r\n",
        "    attention_data = torch.cat(attention_data).to(device)\r\n",
        "    train_val_dataset = TensorDataset(train_data, attention_data, encoded_grades)\r\n",
        "  else:\r\n",
        "    train_val_dataset = TensorDataset(train_data, encoded_grades)\r\n",
        "\r\n",
        "  num_train = round(len(train_val_dataset) * train_proportion)\r\n",
        "  num_val = len(train_val_dataset) - num_train\r\n",
        "  train_dataset, val_dataset = random_split(train_val_dataset, (num_train, num_val))\r\n",
        "\r\n",
        "  # Create dataloaders from the tokenised embeddings\r\n",
        "  train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\r\n",
        "  val_dataloader = DataLoader(val_dataset, sampler=RandomSampler(val_dataset), batch_size=batch_size)\r\n",
        "\r\n",
        "  return train_dataloader, val_dataloader"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdC_r9kcbqnZ"
      },
      "source": [
        "# Models\r\n",
        "\r\n",
        "Below are the model architectures that was at some point part of the testing of the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9nQpept3BQg"
      },
      "source": [
        "# Skeleton BiLSTM model\n",
        "class BiLSTM(nn.Module):\n",
        "  def __init__(self, embedding_dim, hidden_dim, vocab_size, batch_size, device):\n",
        "    super(BiLSTM, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.device = device\n",
        "    self.batch_size = batch_size\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "    # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "    # with dimensionality hidden_dim.\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
        "\n",
        "    # The linear layer that maps from hidden state space to tag space\n",
        "    self.hidden2label = nn.Linear(hidden_dim * 2, 1)\n",
        "    self.hidden = self.init_hidden()\n",
        "\n",
        "  def init_hidden(self):\n",
        "    # Before we've done anything, we dont have any hidden state.\n",
        "    # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\n",
        "    # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
        "    return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device), \\\n",
        "            torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\n",
        "\n",
        "  def forward(self, sentence):\n",
        "    embedded = self.embedding(sentence)\n",
        "    embedded = embedded.permute(1, 0, 2)\n",
        "\n",
        "    lstm_out, self.hidden = self.lstm(\n",
        "        embedded.view(len(embedded), self.batch_size, self.embedding_dim), self.hidden)\n",
        "\n",
        "    out = self.hidden2label(lstm_out[-1])\n",
        "    return out"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaRo-Ma1b62N"
      },
      "source": [
        "# RoBERTa\r\n",
        "class RoBERTa(nn.Module):\r\n",
        "  def __init__(self, embedding_dim, hidden_dim, batch_size, device, roberta_pretrained='roberta-base'):\r\n",
        "    super(RoBERTa, self).__init__()\r\n",
        "    self.hidden_dim = hidden_dim\r\n",
        "    self.embedding_dim = embedding_dim\r\n",
        "    self.device = device\r\n",
        "    self.batch_size = batch_size\r\n",
        "    self.roberta = model = RobertaModel.from_pretrained(roberta_pretrained)\r\n",
        "\r\n",
        "    # The LSTM takes word embeddings as inputs, and outputs hidden states with hidden_dim dimensions\r\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\r\n",
        "    self.hidden2label = nn.Linear(hidden_dim * 2, 1)\r\n",
        "    self.hidden = self.init_hidden()\r\n",
        "\r\n",
        "  def init_hidden(self):\r\n",
        "    # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\r\n",
        "    return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device), \\\r\n",
        "            torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\r\n",
        "\r\n",
        "  def get_embedded(self, sentence):\r\n",
        "    # Returns last hidden layer and pooled output (Linear & tanh) (we're only interested in the hidden layer)\r\n",
        "    outputs = self.roberta(sentence)\r\n",
        "    last_hidden_states = outputs[0]\r\n",
        "    return last_hidden_states\r\n",
        "\r\n",
        "  def forward(self, sentence):\r\n",
        "    embedded = self.get_embedded(sentence)\r\n",
        "\r\n",
        "    # Do I still need this if I'm also training the BERT model?\r\n",
        "    lstm_out, self.hidden = self.lstm(embedded, self.hidden)\r\n",
        "    \r\n",
        "    out = self.hidden2label(lstm_out[-1])\r\n",
        "    return out"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z94C03CgV7h"
      },
      "source": [
        "# Bert\r\n",
        "class BERT(nn.Module):\r\n",
        "  def __init__(self, embedding_dim, hidden_dim, \r\n",
        "                batch_size, device, bert_model=None, bert_pretrained='bert-base-uncased'):\r\n",
        "    super(BERT, self).__init__()\r\n",
        "    self.hidden_dim = hidden_dim\r\n",
        "    self.embedding_dim = embedding_dim\r\n",
        "    self.device = device\r\n",
        "    self.batch_size = batch_size\r\n",
        "    self.bert = BertModel.from_pretrained(bert_pretrained).to(device) if bert_model == None else bert_model\r\n",
        "\r\n",
        "    # The LSTM takes word embeddings as inputs, and outputs hidden states with hidden_dim dimensions\r\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\r\n",
        "    self.hidden2label = nn.Linear(hidden_dim * 2, 1)\r\n",
        "    self.hidden = self.init_hidden()\r\n",
        "\r\n",
        "    # Attention Layer?\r\n",
        "    self.attn_linear = nn.Linear(hidden_dim * 2, 1)\r\n",
        "\r\n",
        "  def init_hidden(self):\r\n",
        "    # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\r\n",
        "    return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device), \\\r\n",
        "            torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\r\n",
        "\r\n",
        "  def get_embedded(self, sentence, grad=True):\r\n",
        "    mask = (sentence != 0).type(torch.long)\r\n",
        "    # Run the text through BERT, and collect all of the hidden states produced from all 12 layers\r\n",
        "    if grad:\r\n",
        "      # The last hidden-state is the first element of the output tuple\r\n",
        "      out = self.bert(sentence, mask)\r\n",
        "      if 'last_hidden_state' in out:\r\n",
        "        last_hidden_states = out['last_hidden_state']\r\n",
        "      elif 'hidden_states' in out:\r\n",
        "        last_hidden_states = out['hidden_states'][-1]\r\n",
        "      else:\r\n",
        "        # Couldn't extract hidden state\r\n",
        "        assert False\r\n",
        "    else:\r\n",
        "      with torch.no_grad():\r\n",
        "        out = self.bert(sentence, mask)\r\n",
        "        if 'last_hidden_state' in out:\r\n",
        "          last_hidden_states = out['last_hidden_state']\r\n",
        "        elif 'hidden_states' in out:\r\n",
        "          last_hidden_states = out['hidden_states'][-1]\r\n",
        "        else:\r\n",
        "          # Couldn't extract hidden state\r\n",
        "          assert False\r\n",
        "\r\n",
        "    return last_hidden_states.type(torch.float32)\r\n",
        "\r\n",
        "  def forward(self, sentence):\r\n",
        "    mask = (sentence != 0).type(torch.long)\r\n",
        "    # Get word embeddings. BERT base gives us 768 hidden parameters for each word.\r\n",
        "    embedded = self.get_embedded(sentence) # (batch_size, max_len)\r\n",
        "\r\n",
        "    # (max_len, batch_size, 768) -> (batch_size, max_len, directions * hidden_dim)\r\n",
        "    lstm_out, self.hidden = self.lstm(embedded, self.hidden)\r\n",
        "\r\n",
        "    # Attention Mechanism\r\n",
        "    # Get similarity using DOT attention (i think)\r\n",
        "    # (batch_size, max_len, directions * hidden_dim) -> (batch_size, max_len)\r\n",
        "    att_out = self.attn_linear(lstm_out).squeeze(-1)\r\n",
        "    # Get the attention weights for each token in a sentence (batch_size)\r\n",
        "    # (batch_size, max_len) -> (batch_size, max_len)\r\n",
        "    # att_out = torch.nn.functional.softmax(att_out, dim=-1)\r\n",
        "    att_out = softmax_mask(att_out, mask)\r\n",
        "    # Get sentence vector which is a weighted sum of token hidden states\r\n",
        "    # (batch_size, max_len) -> (batch_size, directions * hidden_dim)\r\n",
        "    att_out = torch.sum(att_out.unsqueeze(-1) * lstm_out, dim=1)\r\n",
        "    \r\n",
        "    # out = self.hidden2label(lstm_out[-1])\r\n",
        "    out = self.hidden2label(att_out)\r\n",
        "    return out"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnJse9uFu8UH"
      },
      "source": [
        "# Initialisation + Preprocessing\r\n",
        "Prepare the data for training, assign hyperparameters, initialise the models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUKGivqVr7kA"
      },
      "source": [
        "### Prepare Bert and RoBerta specfic Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNTcGaIaJ63d"
      },
      "source": [
        "# Hyperparameters\r\n",
        "bert_type = 'bert-base-uncased'\r\n",
        "rob_type  = 'roberta-base'\r\n",
        "pad_len = 64\r\n",
        "\r\n",
        "e_dim = 768\r\n",
        "h_dim = 50\r\n",
        "\r\n",
        "batch_size = 32\r\n",
        "train_proportion = 0.8"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "3614f8e8c18148a8939cb25058758565",
            "1a2ecc0a67a74b1c8b320968c3d84e1b",
            "f8a6b24ea46c43bdb9d74580f88a3b04",
            "b9dff5ecadd44ef1b41e77ce6b8e2de0",
            "ebee2130adad45fe987ed52c09166881",
            "ce618fb2c58e469daf83a850c7ae4f8b",
            "5e3dc9d911c24a9c831c68bee4e16bb1",
            "99e04808bd204b67ac4d1e983fb43895",
            "0464f16188664658b30e1d0eec4b5275",
            "23efa5c1c4f84bde95257bf219b2bf50",
            "6726c8241a5a488e8fb00655b8e4f47a",
            "3e184066d3864aaf8b8ad2abd46952e7",
            "ce858215b5b64e6bbc5038fea1dd2208",
            "4b21db000c9b491e9bb1f30881864636",
            "d985dd81efee4ddb996fb166c6fba6b4",
            "d0861de5b75042df8b04b1ff4d917fa5",
            "d4fbd2522aed425797c6351009a1fb56",
            "db4d6c1f40e44815b1c9ebaa82249781",
            "08f799298f03483bba9f352da93aef60",
            "0023d6bf3cd44d1bbdf02a4623901912",
            "e85f787243324846a9bf07ebc46bf1e4",
            "f7d1a0c59a78423688b2ab2220b03613",
            "0a3a3db0cdbb42fb82b53c6f4d792ee7",
            "4776cab386e54cfa84f369d069175dd4"
          ]
        },
        "id": "DPzQbQazzoey",
        "outputId": "c2861a68-324b-4049-e8b0-2767abdc28fb"
      },
      "source": [
        "# We set our training data and test data\r\n",
        "training_data = train_df\r\n",
        "test_data = test_df\r\n",
        "\r\n",
        "# Parse training and test data to tuple of original sentences, new sentences, etc.\r\n",
        "x_og, x_new, _, _ = get_sentences(training_data)\r\n",
        "y_og, y_new, _, _ = get_sentences(test_data)\r\n",
        "x_grades = train_df['meanGrade']\r\n",
        "\r\n",
        "# Get Tokenizer for preprocessing\r\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(bert_type, do_lower_case=True)\r\n",
        "rob_tokenizer = RobertaTokenizer.from_pretrained(rob_type)\r\n",
        "\r\n",
        "# Get the dataloaders\r\n",
        "bert_single_train_loader, bert_single_val_loader = encode_edited(x_new, x_grades, bert_tokenizer)\r\n",
        "bert_both_train_loader, bert_both_val_loader = encode_both(x_og, x_new, x_grades, bert_tokenizer)\r\n",
        "robert_single_train_loader, robert_single_val_loader = encode_edited(x_new, x_grades, rob_tokenizer)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3614f8e8c18148a8939cb25058758565",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0464f16188664658b30e1d0eec4b5275",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4fbd2522aed425797c6351009a1fb56",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0IuU_Ijr0cR"
      },
      "source": [
        "### Prepare Glove Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "0Ops2yqW1w1A",
        "outputId": "07379123-15ac-460d-8796-eec644470d98"
      },
      "source": [
        "# Glove embedding based data loading\r\n",
        "# Creating word vectors\r\n",
        "training_vocab, training_tokenized_corpus = create_vocab(training_data)\r\n",
        "test_vocab, test_tokenized_corpus = create_vocab(test_data)\r\n",
        "\r\n",
        "# Creating joint vocab from test and train:\r\n",
        "joint_vocab, joint_tokenized_corpus = create_vocab(pd.concat([training_data, test_data]))\r\n",
        "\r\n",
        "# We create representations for our tokens\r\n",
        "wvecs = [] # word vectors\r\n",
        "word2idx = [] # word2index\r\n",
        "idx2word = []\r\n",
        "\r\n",
        "# This is a large file, it will take a while to load in the memory!\r\n",
        "with codecs.open('glove.6B.100d.txt', 'r','utf-8') as f:\r\n",
        "  index = 1\r\n",
        "  for line in f.readlines():\r\n",
        "    # Ignore the first line - first line typically contains vocab, dimensionality\r\n",
        "    if len(line.strip().split()) > 3:\r\n",
        "      word = line.strip().split()[0]\r\n",
        "      if word in joint_vocab:\r\n",
        "          (word, vec) = (word,\r\n",
        "                     list(map(float,line.strip().split()[1:])))\r\n",
        "          wvecs.append(vec)\r\n",
        "          word2idx.append((word, index))\r\n",
        "          idx2word.append((index, word))\r\n",
        "          index += 1\r\n",
        "\r\n",
        "wvecs = np.array(wvecs)\r\n",
        "word2idx = dict(word2idx)\r\n",
        "idx2word = dict(idx2word)\r\n",
        "\r\n",
        "INPUT_DIM = len(word2idx)\r\n",
        "vectorized_seqs = [[word2idx[tok] for tok in seq if tok in word2idx] for seq in training_tokenized_corpus]\r\n",
        "\r\n",
        "# To avoid any sentences being empty (if no words match to our word embeddings)\r\n",
        "feature = [x if len(x) > 0 else [0] for x in vectorized_seqs]\r\n",
        "\r\n",
        "# 'feature' is a list of lists, each containing embedding IDs for word tokens\r\n",
        "train_and_dev = Task1Dataset(feature, train_df['meanGrade'])\r\n",
        "\r\n",
        "train_examples = round(len(train_and_dev)*train_proportion)\r\n",
        "dev_examples = len(train_and_dev) - train_examples\r\n",
        "\r\n",
        "train_dataset, dev_dataset = random_split(train_and_dev, (train_examples, dev_examples))\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\r\n",
        "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-22f7ec4e7951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# This is a large file, it will take a while to load in the memory!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'glove.6B.100d.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;31m# Force opening of the file in binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'glove.6B.100d.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kDkb9QWvIlq"
      },
      "source": [
        "# Training\r\n",
        "Initialise optimisers and start training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "9l6325m8_qby",
        "outputId": "9594b8d2-99dd-4b8f-c937-190ba708a492"
      },
      "source": [
        "bert_double_pretrained = BertForSequenceClassification.from_pretrained(\r\n",
        "    bert_type, \r\n",
        "    num_labels = 1, # Regression model\r\n",
        ")\r\n",
        "\r\n",
        "bert_double_pretrained = bert_double_pretrained.to(device) # Move to cuda if possible\r\n",
        "bert_double_pretrained = bert_double_pretrained.double() # Convert classifier to regressor\r\n",
        "# Optimizer and Scheduler setup\r\n",
        "optimizer = AdamW(bert_double_pretrained.parameters(), lr=0.0001)\r\n",
        "scheduler = get_linear_schedule_with_warmup(\r\n",
        "    optimizer, \r\n",
        "    num_warmup_steps=0, \r\n",
        "    num_training_steps=(3 * len(bert_both_train_loader))\r\n",
        ")\r\n",
        "\r\n",
        "results = train_bert(bert_both_train_loader, bert_both_val_loader, bert_double_pretrained, 3)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-6fc975a986ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_both_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_both_val_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_double_pretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-25d8285793e5>\u001b[0m in \u001b[0;36mtrain_bert\u001b[0;34m(train_loader, val_loader, model, epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Float but expected Double"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bOlYKQAm28w"
      },
      "source": [
        "### Bert with 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322,
          "referenced_widgets": [
            "5a903ccb05eb41ada7eee57ff792bbd1",
            "0040b42986824244ab8f29a166b8305e",
            "ca0a8306bd5c415d9108077e4f42a210",
            "2ba5775923244a1d8c187fd9980e972a",
            "90746e70e30c44a48dd9f425458a0a12",
            "4d4031ca2a264da094f1cfc7e74a9808",
            "d023217d896f413e888db8c697d53d3f",
            "6f36a3f7d3f8498986e429d2c1eaecfb",
            "475a166de2ff4f57b022c95156d6754b",
            "3774b4101cec42f5baa8258f81dc7ecb",
            "da28d0b8e64942a7b95bbe43f8a27544",
            "b10833ac40af4a6294bd67a6a0acbd5e",
            "9f31c87469c4470980b03a146441a6aa",
            "b682d41ebb4e4aa4b41b86c4629d7b50",
            "292a17e6306f4b92b5f7b73f486c2499",
            "38ca5ec4ffa149c0ba9836625dd56da8"
          ]
        },
        "id": "hDRPb2lEwsOr",
        "outputId": "f9a074ac-c513-43b0-bdff-4713d379afa3"
      },
      "source": [
        "## Bert Training with Both Sentences\r\n",
        "#=====================================#\r\n",
        "# Define run specific hyperparameters #\r\n",
        "#=====================================#\r\n",
        "lr = 2e-5\r\n",
        "epochs = 4\r\n",
        "#=====================================#\r\n",
        "# Load Pretrained Bert model for double sequence training\r\n",
        "bert_double_pretrained = BertForSequenceClassification.from_pretrained(\r\n",
        "    bert_type, \r\n",
        "    num_labels = 1,\r\n",
        "    output_hidden_states = True\r\n",
        ")\r\n",
        "bert_double_pretrained = bert_double_pretrained.to(device) # Move to cuda if possible\r\n",
        "bert_double_pretrained = bert_double_pretrained.double() # Convert classifier to regressor\r\n",
        "\r\n",
        "# Initialise full model\r\n",
        "model = BERT(e_dim, h_dim, batch_size, device, bert_double_pretrained).to(device)\r\n",
        "\r\n",
        "# Optimizer and Scheduler setup\r\n",
        "optimizer = AdamW(model.parameters(), lr=lr)\r\n",
        "scheduler = get_linear_schedule_with_warmup(\r\n",
        "    optimizer, \r\n",
        "    num_warmup_steps=0, \r\n",
        "    num_training_steps=(epochs * len(bert_both_train_loader))\r\n",
        ")\r\n",
        "\r\n",
        "print(\"Model initialised.\")\r\n",
        "\r\n",
        "# Define the loss function\r\n",
        "loss_fn = nn.MSELoss()\r\n",
        "loss_fn = loss_fn.to(device)\r\n",
        "\r\n",
        "results = train(bert_both_train_loader, bert_both_val_loader, model, epochs, loss_fn)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a903ccb05eb41ada7eee57ff792bbd1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "475a166de2ff4f57b022c95156d6754b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model initialised.\n",
            "Training model.\n",
            "| Epoch: 01 | Train Loss: 0.3317 | Train RMSE: 0.5759 | Val. Loss: 0.2848 | Val. RMSE: 0.5337 |\n",
            "| Epoch: 02 | Train Loss: 0.2521 | Train RMSE: 0.5021 | Val. Loss: 0.2961 | Val. RMSE: 0.5441 |\n",
            "| Epoch: 03 | Train Loss: 0.1681 | Train RMSE: 0.4100 | Val. Loss: 0.3228 | Val. RMSE: 0.5682 |\n",
            "| Epoch: 04 | Train Loss: 0.1109 | Train RMSE: 0.3330 | Val. Loss: 0.3218 | Val. RMSE: 0.5673 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "95590144ed2144a699da65e24e68f457",
            "867559c9d5cc429d835e22751bd4bddb",
            "40de6f177ff64acaa92107a74e5eb480",
            "32862ea5d74447eaa97e562bf41fe317",
            "124858509fb4499ca63bd08ae27f407d",
            "ea23f0c0a50444b6821b8412df69d9ec",
            "716f38b2eed34f76af22e157adfbd555",
            "71a0d170505b488b898184713a785208",
            "46d3be4a21434e119f96958201a9df89",
            "32fc129b75bd46bdbbc54072ba887f40",
            "11aceda189ec44619162f061175875e7",
            "128f99a2a63d45038d654049a108504a",
            "f0dde8b70c6946a39737400f5da469aa",
            "94d947d7795146f58727f04d57d4f5d1",
            "e21021c22d854d83a2f939f113789813",
            "45e2b02e8f274b2d92e97d712118acc7"
          ]
        },
        "id": "defpiqYCxvNN",
        "outputId": "5f7bacec-02d5-457e-c670-d9160853ede8"
      },
      "source": [
        "## Bert Training with Single Sentence\r\n",
        "#=====================================#\r\n",
        "# Define run specific hyperparameters #\r\n",
        "#=====================================#\r\n",
        "lr = 2e-5\r\n",
        "epochs = 4\r\n",
        "#=====================================#\r\n",
        "# Initialise full model\r\n",
        "model = BERT(e_dim, h_dim, batch_size, device).to(device)\r\n",
        "\r\n",
        "# Optimizer and Scheduler setup\r\n",
        "optimizer = AdamW(model.parameters(), lr=lr)\r\n",
        "scheduler = get_linear_schedule_with_warmup(\r\n",
        "    optimizer, \r\n",
        "    num_warmup_steps=0, \r\n",
        "    num_training_steps=(epochs * len(bert_single_train_loader))\r\n",
        ")\r\n",
        "print(\"Model initialised.\")\r\n",
        "\r\n",
        "# Define the loss function\r\n",
        "loss_fn = nn.MSELoss()\r\n",
        "loss_fn = loss_fn.to(device)\r\n",
        "\r\n",
        "results = train(bert_single_train_loader, bert_single_val_loader, model, epochs, loss_fn)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95590144ed2144a699da65e24e68f457",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46d3be4a21434e119f96958201a9df89",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Model initialised.\n",
            "Training model.\n",
            "| Epoch: 01 | Train Loss: 0.3373 | Train RMSE: 0.5807 | Val. Loss: 0.2923 | Val. RMSE: 0.5407 |\n",
            "| Epoch: 02 | Train Loss: 0.2529 | Train RMSE: 0.5029 | Val. Loss: 0.2808 | Val. RMSE: 0.5299 |\n",
            "| Epoch: 03 | Train Loss: 0.1750 | Train RMSE: 0.4184 | Val. Loss: 0.3125 | Val. RMSE: 0.5590 |\n",
            "| Epoch: 04 | Train Loss: 0.1152 | Train RMSE: 0.3394 | Val. Loss: 0.3220 | Val. RMSE: 0.5674 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "OB0zCYH11jJp",
        "outputId": "8b47144c-6996-440c-bc5b-9f67dc86d1c8"
      },
      "source": [
        "## Roberta Training\r\n",
        "#=====================================#\r\n",
        "# Define run specific hyperparameters #\r\n",
        "#=====================================#\r\n",
        "lr = 0.001\r\n",
        "epochs = 3\r\n",
        "#=====================================#\r\n",
        "model = RoBERTa(e_dim, h_dim, batch_size, device).to(device)\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters())\r\n",
        "\r\n",
        "print(\"Model initialised.\")\r\n",
        "\r\n",
        "# Define the loss function\r\n",
        "loss_fn = nn.MSELoss()\r\n",
        "loss_fn = loss_fn.to(device)\r\n",
        "\r\n",
        "print(\"Model initialised.\")\r\n",
        "results = train(robert_single_train_loader, robert_single_val_loader, model, epochs, loss_fn)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model initialised.\n",
            "Model initialised.\n",
            "Training model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([149])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-df0c63e6dd16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model initialised.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrobert_single_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrobert_single_val_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-eaa0cba98a00>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_iter, dev_iter, model, number_epoch, loss_fn)\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m       \u001b[0msse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2657\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (149) must match the size of tensor b (32) at non-singleton dimension 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "0_4Benjk3BQg",
        "outputId": "706b17d3-b5a1-4f00-c689-f7927e12aa66"
      },
      "source": [
        "## Approach 1 code, using functions defined above:\n",
        "\n",
        "#=====================================#\n",
        "# Define run specific hyperparameters #\n",
        "#=====================================#\n",
        "lr = 0.001\n",
        "epochs = 6\n",
        "#=====================================#\n",
        "\n",
        "model = BiLSTM(e_dim, h_dim, INPUT_DIM, batch_size, device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "model.to(device)\n",
        "\n",
        "# We provide the model with our embeddings\n",
        "model.embedding.weight.data.copy_(torch.from_numpy(wvecs))\n",
        "\n",
        "# Define the loss function\n",
        "loss_fn = nn.MSELoss()\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "print(\"Model initialised.\")\n",
        "results = train(train_loader, dev_loader, model, epochs, loss_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab created.\n",
            "Model initialised.\n",
            "Dataloaders created.\n",
            "Training model.\n",
            "| Epoch: 01 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
            "| Epoch: 02 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
            "| Epoch: 03 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
            "| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
            "| Epoch: 05 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
            "| Epoch: 06 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
            "| Epoch: 07 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.38 | Val. MSE: 0.38 |  Val. RMSE: 0.62 |\n",
            "| Epoch: 08 | Train Loss: 0.24 | Train MSE: 0.24 | Train RMSE: 0.49 |         Val. Loss: 0.37 | Val. MSE: 0.37 |  Val. RMSE: 0.61 |\n",
            "| Epoch: 09 | Train Loss: 0.23 | Train MSE: 0.23 | Train RMSE: 0.48 |         Val. Loss: 0.38 | Val. MSE: 0.38 |  Val. RMSE: 0.62 |\n",
            "| Epoch: 10 | Train Loss: 0.22 | Train MSE: 0.22 | Train RMSE: 0.47 |         Val. Loss: 0.39 | Val. MSE: 0.39 |  Val. RMSE: 0.63 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahuFb8KU3BQi"
      },
      "source": [
        "#### Approach 2: No pre-trained representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewkWUrP33BQj",
        "outputId": "1539c4f1-4122-41ea-b299-f4c91a1c6b65"
      },
      "source": [
        "train_and_dev = train_df['edit']\n",
        "\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(train_df['edit'], train_df['meanGrade'],\n",
        "                                                                        test_size=(1-train_proportion),\n",
        "                                                                        random_state=42)\n",
        "\n",
        "# We train a Tf-idf model\n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "train_counts = count_vect.fit_transform(training_data)\n",
        "transformer = TfidfTransformer().fit(train_counts)\n",
        "train_counts = transformer.transform(train_counts)\n",
        "regression_model = LinearRegression().fit(train_counts, training_y)\n",
        "\n",
        "# Train predictions\n",
        "predicted_train = regression_model.predict(train_counts)\n",
        "\n",
        "# Calculate Tf-idf using train and dev, and validate model on dev:\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\n",
        "\n",
        "test_counts = count_vect.transform(dev_data)\n",
        "\n",
        "test_counts = transformer.transform(test_counts)\n",
        "\n",
        "# Dev predictions\n",
        "predicted = regression_model.predict(test_counts)\n",
        "\n",
        "# We run the evaluation:\n",
        "print(\"\\nTrain performance:\")\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\n",
        "\n",
        "print(\"\\nDev performance:\")\n",
        "sse, mse = model_performance(predicted, dev_y, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train performance:\n",
            "| MSE: 0.13 | RMSE: 0.37 |\n",
            "\n",
            "Dev performance:\n",
            "| MSE: 0.36 | RMSE: 0.60 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA5bYyuG3BQj"
      },
      "source": [
        "#### Baseline for task 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72fIC0-I3BQk",
        "outputId": "d01b6da1-0c83-4f30-cdcc-a18c4c21798c"
      },
      "source": [
        "# Baseline for the task\n",
        "pred_baseline = torch.zeros(len(dev_y)) + np.mean(training_y)\n",
        "print(\"\\nBaseline performance:\")\n",
        "sse, mse = model_performance(pred_baseline, dev_y, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Baseline performance:\n",
            "| MSE: 0.34 | RMSE: 0.58 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz1VVAIG0hyv"
      },
      "source": [
        "# Deprecated Code\r\n",
        "\r\n",
        "Kept temporarily until the devs are ready to delete forever :D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDHlDBubKC9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "e47c611966844eadb2cfe926673e494e",
            "47c919f5b011483d8b602ba956990374",
            "671f316ee5f2465eaf5267a1976b24e8",
            "d5b7596f16804eeb8f8dd3b1073a06be",
            "98c6870f0bc449b39f9d8653aa8d27cd",
            "8ac8e41d5b5f4ebb86a4531f549c435b",
            "333167d4cc56449fa4869d2122c09135",
            "78629d0ac788406b9c48e0074556096c"
          ]
        },
        "outputId": "a9187c47-e01f-4435-ae1c-46e216552a22"
      },
      "source": [
        "# We set our training data and test data\r\n",
        "training_data = train_df\r\n",
        "test_data = test_df\r\n",
        "\r\n",
        "# Parse training and test data to tuple of original sentences, new sentences, etc.\r\n",
        "x_og, x_new, _, _ = get_sentences(training_data)\r\n",
        "y_og, y_new, _, _ = get_sentences(test_data)\r\n",
        "\r\n",
        "# Bert Preprocessing\r\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_type, do_lower_case=True)\r\n",
        "\r\n",
        "# Tokenise sentences and add special Bert tokens as necessary\r\n",
        "train_input = []\r\n",
        "train_masks = []\r\n",
        "test_input  = []\r\n",
        "test_masks  = []\r\n",
        "train_grades = train_df['meanGrade']\r\n",
        "for og, new in zip(x_og, x_new):\r\n",
        "  encoded_plus = tokenizer.encode_plus(og, text_pair=new, max_length=pad_len, \r\n",
        "                                       truncation=True, padding='max_length', return_tensors='pt')\r\n",
        "  train_input.append(encoded_plus['input_ids'])\r\n",
        "  train_masks.append(encoded_plus['attention_mask'])\r\n",
        "\r\n",
        "# Tokenise Test set\r\n",
        "for og, new in zip(y_og, y_new):\r\n",
        "  encoded_plus = tokenizer.encode_plus(og, text_pair=new, max_length=pad_len, \r\n",
        "                                       truncation=True, padding='max_length', return_tensors='pt')\r\n",
        "  test_input.append(encoded_plus['input_ids'])\r\n",
        "  test_masks.append(encoded_plus['attention_mask'])\r\n",
        "\r\n",
        "# Convert to Tensors\r\n",
        "train_input = torch.cat(train_input)\r\n",
        "train_masks = torch.cat(train_masks)\r\n",
        "train_grades = torch.tensor(train_grades)\r\n",
        "test_input  = torch.cat(test_input)\r\n",
        "test_masks  = torch.cat(test_masks)\r\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e47c611966844eadb2cfe926673e494e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS4IYQ8Tq7x9"
      },
      "source": [
        "# Split train dataset to train and validation sets\r\n",
        "train_val_dataset = TensorDataset(train_input, train_masks, train_grades)\r\n",
        "num_train = round(len(train_val_dataset) * train_proportion)\r\n",
        "num_val = len(train_val_dataset) - num_train\r\n",
        "train_dataset, val_dataset = random_split(train_val_dataset, (num_train, num_val))\r\n",
        "\r\n",
        "# Create dataloaders from the tokenised embeddings\r\n",
        "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\r\n",
        "val_dataloader = DataLoader(val_dataset, sampler=RandomSampler(val_dataset), batch_size=batch_size)"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}